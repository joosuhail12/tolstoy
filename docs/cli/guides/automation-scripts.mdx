---
title: "CLI Automation Scripts"
description: "Build powerful automation scripts using the Tolstoy CLI with practical examples for deployment, monitoring, and workflow management."
---

# CLI Automation Scripts

Learn to build powerful automation scripts that leverage the Tolstoy CLI for workflow deployment, monitoring, alerting, and operational tasks. This guide provides practical, production-ready examples.

## Script Development Principles

### Design Guidelines

1. **Idempotent Operations**: Scripts should produce the same result when run multiple times
2. **Error Handling**: Always handle and report errors gracefully
3. **Logging**: Provide clear, actionable log output
4. **Configuration**: Make scripts configurable via environment variables or files
5. **Testing**: Include validation and dry-run capabilities

### Script Template

```bash
#!/bin/bash

# Script: workflow-deployment.sh
# Purpose: Deploy workflows to Tolstoy with validation and rollback
# Author: DevOps Team
# Version: 1.0

set -euo pipefail  # Exit on error, undefined vars, pipe failures

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_FILE="${LOG_FILE:-/tmp/tolstoy-deploy-$(date +%Y%m%d-%H%M%S).log}"
DRY_RUN="${DRY_RUN:-false}"
VERBOSE="${VERBOSE:-false}"

# Logging functions
log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "$LOG_FILE"; }
error() { log "ERROR: $*" >&2; }
info() { log "INFO: $*"; }
debug() { [[ "$VERBOSE" == "true" ]] && log "DEBUG: $*"; }

# Validation function
validate_prerequisites() {
    info "Validating prerequisites..."
    
    # Check if Tolstoy CLI is installed
    if ! command -v tolstoy &> /dev/null; then
        error "Tolstoy CLI is not installed"
        return 1
    fi
    
    # Test configuration
    if ! tolstoy config test --timeout 10s; then
        error "Tolstoy CLI configuration test failed"
        return 1
    fi
    
    info "Prerequisites validated successfully"
}

# Main function
main() {
    info "Starting workflow deployment script"
    
    validate_prerequisites
    
    # Your script logic here
    
    info "Script completed successfully"
}

# Error handling
trap 'error "Script failed at line $LINENO"' ERR

# Help function
show_help() {
    cat << EOF
Usage: $0 [OPTIONS]

Options:
    -h, --help       Show this help message
    -v, --verbose    Enable verbose output
    -n, --dry-run    Perform dry run without making changes
    
Environment Variables:
    LOG_FILE         Path to log file (default: /tmp/tolstoy-deploy-timestamp.log)
    DRY_RUN         Set to 'true' for dry run mode
    VERBOSE         Set to 'true' for verbose output

Examples:
    $0                          # Normal execution
    $0 --dry-run --verbose      # Dry run with verbose output
    VERBOSE=true $0             # Using environment variable
EOF
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            show_help
            exit 0
            ;;
        -v|--verbose)
            VERBOSE="true"
            shift
            ;;
        -n|--dry-run)
            DRY_RUN="true"
            shift
            ;;
        *)
            error "Unknown option: $1"
            show_help
            exit 1
            ;;
    esac
done

# Run main function if script is executed directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
```

## Workflow Deployment Scripts

### Basic Deployment Script

```bash
#!/bin/bash
# deploy-workflows.sh - Deploy workflows from directory

set -euo pipefail

WORKFLOWS_DIR="${1:-./workflows}"
ENVIRONMENT="${2:-development}"
BACKUP_DIR="${BACKUP_DIR:-./backups}"

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"; }
error() { log "ERROR: $*" >&2; }
info() { log "INFO: $*"; }

# Switch to environment profile
info "Switching to $ENVIRONMENT environment"
tolstoy config use "$ENVIRONMENT"

# Validate configuration
if ! tolstoy config test --timeout 10s; then
    error "Failed to connect to $ENVIRONMENT environment"
    exit 1
fi

# Create backup directory
mkdir -p "$BACKUP_DIR/$(date +%Y%m%d-%H%M%S)"

# Deploy workflows
info "Deploying workflows from $WORKFLOWS_DIR"

for workflow_file in "$WORKFLOWS_DIR"/*.yml "$WORKFLOWS_DIR"/*.yaml; do
    [[ -f "$workflow_file" ]] || continue
    
    workflow_name=$(basename "$workflow_file" .yml)
    workflow_name=${workflow_name%.yaml}
    
    info "Processing workflow: $workflow_name"
    
    # Validate workflow file
    if ! tolstoy flows validate "$workflow_file"; then
        error "Validation failed for $workflow_name"
        continue
    fi
    
    # Check if workflow exists
    if tolstoy flows get "$workflow_name" --quiet 2>/dev/null; then
        # Backup existing workflow
        info "Backing up existing workflow: $workflow_name"
        tolstoy flows get "$workflow_name" --output yaml > "$BACKUP_DIR/$(date +%Y%m%d-%H%M%S)/$workflow_name.yml"
        
        # Update existing workflow
        info "Updating workflow: $workflow_name"
        tolstoy flows update "$workflow_name" "$workflow_file"
    else
        # Create new workflow
        info "Creating new workflow: $workflow_name"
        tolstoy flows create "$workflow_file"
    fi
    
    # Verify deployment
    if tolstoy flows get "$workflow_name" --quiet; then
        info "✅ Successfully deployed: $workflow_name"
    else
        error "❌ Failed to deploy: $workflow_name"
    fi
done

info "Workflow deployment completed"
```

### Advanced Deployment with Rollback

```bash
#!/bin/bash
# advanced-deploy.sh - Advanced deployment with rollback capability

set -euo pipefail

WORKFLOWS_DIR="${1:-./workflows}"
ENVIRONMENT="${2:-development}"
BACKUP_DIR="./backups/$(date +%Y%m%d-%H%M%S)"
DEPLOYMENT_LOG="$BACKUP_DIR/deployment.log"
ROLLBACK_SCRIPT="$BACKUP_DIR/rollback.sh"

# Tracking arrays
DEPLOYED_WORKFLOWS=()
FAILED_WORKFLOWS=()

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "$DEPLOYMENT_LOG"; }
error() { log "ERROR: $*" >&2; }
info() { log "INFO: $*"; }

# Setup
setup_deployment() {
    info "Setting up deployment environment"
    mkdir -p "$BACKUP_DIR"
    
    # Initialize rollback script
    cat > "$ROLLBACK_SCRIPT" << 'EOF'
#!/bin/bash
# Auto-generated rollback script
set -euo pipefail

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] ROLLBACK: $*"; }
EOF
    chmod +x "$ROLLBACK_SCRIPT"
    
    # Switch environment
    tolstoy config use "$ENVIRONMENT"
    
    if ! tolstoy config test --timeout 10s; then
        error "Failed to connect to $ENVIRONMENT"
        exit 1
    fi
}

# Deploy single workflow
deploy_workflow() {
    local workflow_file="$1"
    local workflow_name=$(basename "$workflow_file" .yml)
    workflow_name=${workflow_name%.yaml}
    
    info "Deploying workflow: $workflow_name"
    
    # Validate workflow
    if ! tolstoy flows validate "$workflow_file"; then
        error "Validation failed: $workflow_name"
        FAILED_WORKFLOWS+=("$workflow_name")
        return 1
    fi
    
    # Backup existing workflow if it exists
    if tolstoy flows get "$workflow_name" --quiet 2>/dev/null; then
        info "Backing up existing workflow: $workflow_name"
        tolstoy flows get "$workflow_name" --output yaml > "$BACKUP_DIR/$workflow_name.yml"
        
        # Add to rollback script
        cat >> "$ROLLBACK_SCRIPT" << EOF
log "Restoring workflow: $workflow_name"
tolstoy flows update "$workflow_name" "$BACKUP_DIR/$workflow_name.yml"
EOF
        
        # Update workflow
        if tolstoy flows update "$workflow_name" "$workflow_file"; then
            info "✅ Updated workflow: $workflow_name"
            DEPLOYED_WORKFLOWS+=("$workflow_name")
        else
            error "❌ Failed to update workflow: $workflow_name"
            FAILED_WORKFLOWS+=("$workflow_name")
            return 1
        fi
    else
        # Create new workflow
        if tolstoy flows create "$workflow_file"; then
            info "✅ Created workflow: $workflow_name"
            DEPLOYED_WORKFLOWS+=("$workflow_name")
            
            # Add to rollback script
            cat >> "$ROLLBACK_SCRIPT" << EOF
log "Deleting workflow: $workflow_name"  
tolstoy flows delete "$workflow_name" --confirm
EOF
        else
            error "❌ Failed to create workflow: $workflow_name"
            FAILED_WORKFLOWS+=("$workflow_name")
            return 1
        fi
    fi
}

# Validate all deployments
validate_deployments() {
    info "Validating all deployed workflows"
    local validation_failed=false
    
    for workflow in "${DEPLOYED_WORKFLOWS[@]}"; do
        info "Testing workflow: $workflow"
        
        # Test with sample empty input (dry run)
        if ! tolstoy flows execute "$workflow" --input '{}' --dry-run --timeout 30s; then
            error "Post-deployment validation failed: $workflow"
            validation_failed=true
        fi
    done
    
    if [[ "$validation_failed" == "true" ]]; then
        error "Post-deployment validation failed for some workflows"
        return 1
    fi
    
    info "All deployed workflows validated successfully"
}

# Rollback function
perform_rollback() {
    error "Deployment failed, initiating rollback"
    
    if [[ -f "$ROLLBACK_SCRIPT" ]] && [[ ${#DEPLOYED_WORKFLOWS[@]} -gt 0 ]]; then
        info "Executing rollback script: $ROLLBACK_SCRIPT"
        bash "$ROLLBACK_SCRIPT"
        
        info "Rollback completed. Check logs: $DEPLOYMENT_LOG"
    else
        info "No rollback needed - no workflows were successfully deployed"
    fi
}

# Main deployment function
main() {
    info "Starting advanced workflow deployment"
    
    setup_deployment
    
    # Deploy all workflows
    local deployment_success=true
    for workflow_file in "$WORKFLOWS_DIR"/*.yml "$WORKFLOWS_DIR"/*.yaml; do
        [[ -f "$workflow_file" ]] || continue
        
        if ! deploy_workflow "$workflow_file"; then
            deployment_success=false
            # Continue deploying other workflows
        fi
    done
    
    # Validate deployments if any succeeded
    if [[ ${#DEPLOYED_WORKFLOWS[@]} -gt 0 ]]; then
        if ! validate_deployments; then
            deployment_success=false
        fi
    fi
    
    # Handle deployment result
    if [[ "$deployment_success" == "true" ]]; then
        info "🎉 Deployment completed successfully"
        info "Deployed workflows: ${DEPLOYED_WORKFLOWS[*]}"
        info "Backup location: $BACKUP_DIR"
        info "Rollback script: $ROLLBACK_SCRIPT"
    else
        error "Deployment had failures"
        if [[ ${#FAILED_WORKFLOWS[@]} -gt 0 ]]; then
            error "Failed workflows: ${FAILED_WORKFLOWS[*]}"
        fi
        
        # Ask for rollback confirmation
        read -p "Do you want to rollback successful deployments? (y/N): " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            perform_rollback
        fi
        
        exit 1
    fi
}

# Error handling
trap 'error "Deployment failed at line $LINENO"' ERR

main "$@"
```

## Monitoring and Alerting Scripts

### Health Monitoring Script

```bash
#!/bin/bash
# monitor-health.sh - Comprehensive health monitoring

set -euo pipefail

ALERT_THRESHOLD_SUCCESS_RATE=90
ALERT_THRESHOLD_RESPONSE_TIME=5000  # milliseconds
ALERT_EMAIL="${ALERT_EMAIL:-ops@company.com}"
SLACK_WEBHOOK="${SLACK_WEBHOOK:-}"

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"; }
error() { log "ERROR: $*" >&2; }
info() { log "INFO: $*"; }

# Check overall system health
check_system_health() {
    info "Checking system health..."
    
    local health_output
    if ! health_output=$(tolstoy config test --json 2>/dev/null); then
        error "System health check failed"
        return 1
    fi
    
    local status
    status=$(echo "$health_output" | jq -r '.status // "unknown"')
    
    case "$status" in
        "ok")
            info "✅ System health: OK"
            return 0
            ;;
        "degraded")
            log "⚠️ System health: DEGRADED"
            return 1
            ;;
        *)
            error "❌ System health: CRITICAL"
            return 2
            ;;
    esac
}

# Check workflow execution health
check_execution_health() {
    info "Checking workflow execution health..."
    
    # Get execution statistics for last hour
    local stats_output
    if ! stats_output=$(tolstoy logs stats --since 1h --format json 2>/dev/null); then
        error "Failed to get execution statistics"
        return 1
    fi
    
    local success_rate response_time
    success_rate=$(echo "$stats_output" | jq -r '.overall.success_rate // 0' | cut -d. -f1)
    response_time=$(echo "$stats_output" | jq -r '.overall.avg_response_time_ms // 0' | cut -d. -f1)
    
    info "Success rate: ${success_rate}%"
    info "Average response time: ${response_time}ms"
    
    local issues=()
    
    if (( success_rate < ALERT_THRESHOLD_SUCCESS_RATE )); then
        issues+=("Low success rate: ${success_rate}% (threshold: ${ALERT_THRESHOLD_SUCCESS_RATE}%)")
    fi
    
    if (( response_time > ALERT_THRESHOLD_RESPONSE_TIME )); then
        issues+=("High response time: ${response_time}ms (threshold: ${ALERT_THRESHOLD_RESPONSE_TIME}ms)")
    fi
    
    if [[ ${#issues[@]} -gt 0 ]]; then
        error "Execution health issues detected:"
        printf '%s\n' "${issues[@]}"
        return 1
    fi
    
    info "✅ Execution health: OK"
    return 0
}

# Check tool connectivity
check_tool_health() {
    info "Checking tool connectivity..."
    
    local tools_output
    if ! tools_output=$(tolstoy tools health --all --format json 2>/dev/null); then
        error "Failed to get tool health"
        return 1
    fi
    
    local failed_tools
    failed_tools=$(echo "$tools_output" | jq -r '.tools[] | select(.status != "healthy") | .name' | tr '\n' ' ')
    
    if [[ -n "$failed_tools" ]]; then
        error "Unhealthy tools detected: $failed_tools"
        return 1
    fi
    
    info "✅ All tools healthy"
    return 0
}

# Send alert notification
send_alert() {
    local message="$1"
    local severity="${2:-warning}"
    
    info "Sending alert: $message"
    
    # Send email alert
    if [[ -n "$ALERT_EMAIL" ]]; then
        echo "$message" | mail -s "Tolstoy Health Alert [$severity]" "$ALERT_EMAIL" || true
    fi
    
    # Send Slack alert
    if [[ -n "$SLACK_WEBHOOK" ]]; then
        local payload
        payload=$(jq -n \
            --arg text "$message" \
            --arg severity "$severity" \
            '{
                text: $text,
                channel: "#alerts",
                username: "Tolstoy Monitor",
                icon_emoji: ":warning:",
                attachments: [{
                    color: ($severity == "critical" | if . then "danger" elif $severity == "warning" then "warning" else "good" end),
                    fields: [{
                        title: "Severity",
                        value: $severity,
                        short: true
                    }, {
                        title: "Timestamp", 
                        value: (now | strftime("%Y-%m-%d %H:%M:%S UTC")),
                        short: true
                    }]
                }]
            }'
        )
        
        curl -X POST \
            -H "Content-Type: application/json" \
            -d "$payload" \
            "$SLACK_WEBHOOK" || true
    fi
}

# Generate health report
generate_health_report() {
    local report_file="/tmp/tolstoy-health-report-$(date +%Y%m%d-%H%M%S).md"
    
    info "Generating health report: $report_file"
    
    cat > "$report_file" << EOF
# Tolstoy Health Report

**Generated:** $(date)

## System Status

EOF
    
    # Add system health
    if check_system_health >> "$report_file" 2>&1; then
        echo "✅ System: Healthy" >> "$report_file"
    else
        echo "❌ System: Issues detected" >> "$report_file"
    fi
    
    # Add execution health  
    echo -e "\n## Execution Health\n" >> "$report_file"
    tolstoy logs stats --since 24h --format markdown >> "$report_file" 2>/dev/null || echo "Failed to get execution stats" >> "$report_file"
    
    # Add tool health
    echo -e "\n## Tool Health\n" >> "$report_file"
    tolstoy tools health --all --format markdown >> "$report_file" 2>/dev/null || echo "Failed to get tool health" >> "$report_file"
    
    # Add recent errors
    echo -e "\n## Recent Errors\n" >> "$report_file"
    tolstoy logs search "error\|failed" --since 4h --limit 10 >> "$report_file" 2>/dev/null || echo "No recent errors found" >> "$report_file"
    
    echo "$report_file"
}

# Main monitoring function
main() {
    info "Starting Tolstoy health monitoring"
    
    local health_issues=()
    
    # Check system health
    if ! check_system_health; then
        health_issues+=("System health check failed")
    fi
    
    # Check execution health
    if ! check_execution_health; then
        health_issues+=("Execution health issues")
    fi
    
    # Check tool health
    if ! check_tool_health; then
        health_issues+=("Tool connectivity issues")
    fi
    
    # Handle results
    if [[ ${#health_issues[@]} -gt 0 ]]; then
        local alert_message="Tolstoy health monitoring detected issues:\n"
        printf -v alert_message "%s\n- %s" "$alert_message" "${health_issues[@]}"
        
        error "Health monitoring detected ${#health_issues[@]} issue(s)"
        send_alert "$alert_message" "warning"
        
        # Generate detailed report
        local report_file
        report_file=$(generate_health_report)
        info "Detailed report: $report_file"
        
        exit 1
    else
        info "✅ All health checks passed"
        
        # Send daily success report if it's morning
        if [[ $(date +%H) == "09" ]]; then
            send_alert "Daily health check: All systems operational" "info"
        fi
    fi
}

main "$@"
```

### Automated Workflow Execution Script

```bash
#!/bin/bash
# batch-execute.sh - Execute workflows in batch with monitoring

set -euo pipefail

WORKFLOWS_FILE="${1:-workflows.txt}"
BATCH_SIZE="${BATCH_SIZE:-5}"
PARALLEL_EXECUTION="${PARALLEL_EXECUTION:-false}"
RESULTS_DIR="./results/$(date +%Y%m%d-%H%M%S)"

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "$RESULTS_DIR/execution.log"; }
error() { log "ERROR: $*" >&2; }
info() { log "INFO: $*"; }

# Results tracking
SUCCESSFUL_EXECUTIONS=()
FAILED_EXECUTIONS=()
EXECUTION_TIMES=()

# Setup results directory
setup_results_dir() {
    mkdir -p "$RESULTS_DIR"
    info "Results will be saved to: $RESULTS_DIR"
}

# Execute single workflow
execute_workflow() {
    local workflow_id="$1"
    local input_data="$2"
    local execution_id result_file start_time end_time duration
    
    result_file="$RESULTS_DIR/${workflow_id}_$(date +%H%M%S).json"
    start_time=$(date +%s)
    
    info "Executing workflow: $workflow_id"
    
    # Execute workflow and capture execution ID
    if execution_output=$(tolstoy flows execute "$workflow_id" \
        --input "$input_data" \
        --output json \
        --timeout 300s 2>&1); then
        
        end_time=$(date +%s)
        duration=$((end_time - start_time))
        
        # Save results
        echo "$execution_output" > "$result_file"
        
        execution_id=$(echo "$execution_output" | jq -r '.execution_id // "unknown"')
        
        info "✅ Workflow completed: $workflow_id (${duration}s) - ID: $execution_id"
        
        SUCCESSFUL_EXECUTIONS+=("$workflow_id:$execution_id:${duration}s")
        EXECUTION_TIMES+=("$duration")
        
        return 0
    else
        end_time=$(date +%s)
        duration=$((end_time - start_time))
        
        # Save error details
        echo "$execution_output" > "${result_file}.error"
        
        error "❌ Workflow failed: $workflow_id (${duration}s)"
        FAILED_EXECUTIONS+=("$workflow_id:${duration}s")
        
        return 1
    fi
}

# Execute workflows in parallel batch
execute_batch_parallel() {
    local batch=("$@")
    local pids=()
    
    info "Executing batch of ${#batch[@]} workflows in parallel"
    
    for workflow_spec in "${batch[@]}"; do
        IFS=':' read -r workflow_id input_data <<< "$workflow_spec"
        
        # Execute in background
        execute_workflow "$workflow_id" "$input_data" &
        pids+=($!)
    done
    
    # Wait for all background processes
    for pid in "${pids[@]}"; do
        wait "$pid" || true  # Continue even if some fail
    done
}

# Execute workflows sequentially  
execute_batch_sequential() {
    local batch=("$@")
    
    info "Executing batch of ${#batch[@]} workflows sequentially"
    
    for workflow_spec in "${batch[@]}"; do
        IFS=':' read -r workflow_id input_data <<< "$workflow_spec"
        execute_workflow "$workflow_id" "$input_data"
    done
}

# Generate execution report
generate_execution_report() {
    local report_file="$RESULTS_DIR/execution_report.md"
    
    info "Generating execution report: $report_file"
    
    cat > "$report_file" << EOF
# Batch Execution Report

**Execution Time:** $(date)  
**Total Workflows:** $((${#SUCCESSFUL_EXECUTIONS[@]} + ${#FAILED_EXECUTIONS[@]}))  
**Successful:** ${#SUCCESSFUL_EXECUTIONS[@]}  
**Failed:** ${#FAILED_EXECUTIONS[@]}  
**Success Rate:** $(( ${#SUCCESSFUL_EXECUTIONS[@]} * 100 / (${#SUCCESSFUL_EXECUTIONS[@]} + ${#FAILED_EXECUTIONS[@]}) ))%

## Execution Statistics

EOF

    if [[ ${#EXECUTION_TIMES[@]} -gt 0 ]]; then
        local total_time=0
        local min_time=999999
        local max_time=0
        
        for time in "${EXECUTION_TIMES[@]}"; do
            total_time=$((total_time + time))
            [[ $time -lt $min_time ]] && min_time=$time
            [[ $time -gt $max_time ]] && max_time=$time
        done
        
        local avg_time=$((total_time / ${#EXECUTION_TIMES[@]}))
        
        cat >> "$report_file" << EOF
- **Total Execution Time:** ${total_time}s
- **Average Execution Time:** ${avg_time}s  
- **Fastest Execution:** ${min_time}s
- **Slowest Execution:** ${max_time}s

EOF
    fi
    
    # Successful executions
    if [[ ${#SUCCESSFUL_EXECUTIONS[@]} -gt 0 ]]; then
        cat >> "$report_file" << EOF
## Successful Executions

| Workflow | Execution ID | Duration |
|----------|--------------|----------|
EOF
        
        for execution in "${SUCCESSFUL_EXECUTIONS[@]}"; do
            IFS=':' read -r workflow_id execution_id duration <<< "$execution"
            echo "| $workflow_id | $execution_id | $duration |" >> "$report_file"
        done
        
        echo >> "$report_file"
    fi
    
    # Failed executions
    if [[ ${#FAILED_EXECUTIONS[@]} -gt 0 ]]; then
        cat >> "$report_file" << EOF
## Failed Executions

| Workflow | Duration | Error Details |
|----------|----------|---------------|
EOF
        
        for execution in "${FAILED_EXECUTIONS[@]}"; do
            IFS=':' read -r workflow_id duration <<< "$execution"
            echo "| $workflow_id | $duration | See ${workflow_id}_*.error file |" >> "$report_file"
        done
    fi
    
    echo "$report_file"
}

# Main execution function
main() {
    info "Starting batch workflow execution"
    
    setup_results_dir
    
    # Read workflows file
    if [[ ! -f "$WORKFLOWS_FILE" ]]; then
        error "Workflows file not found: $WORKFLOWS_FILE"
        exit 1
    fi
    
    # Process workflows in batches
    local batch=()
    local line_count=0
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        [[ "$line" =~ ^[[:space:]]*$ ]] && continue  # Skip empty lines
        [[ "$line" =~ ^[[:space:]]*# ]] && continue  # Skip comments
        
        batch+=("$line")
        line_count=$((line_count + 1))
        
        # Process batch when it reaches batch size
        if [[ ${#batch[@]} -eq $BATCH_SIZE ]]; then
            if [[ "$PARALLEL_EXECUTION" == "true" ]]; then
                execute_batch_parallel "${batch[@]}"
            else
                execute_batch_sequential "${batch[@]}"
            fi
            
            batch=()
        fi
    done < "$WORKFLOWS_FILE"
    
    # Process remaining workflows in final batch
    if [[ ${#batch[@]} -gt 0 ]]; then
        if [[ "$PARALLEL_EXECUTION" == "true" ]]; then
            execute_batch_parallel "${batch[@]}"
        else
            execute_batch_sequential "${batch[@]}"
        fi
    fi
    
    # Generate report
    local report_file
    report_file=$(generate_execution_report)
    
    info "Batch execution completed"
    info "Processed $line_count workflows"
    info "Report: $report_file"
    
    # Exit with error if any workflows failed
    if [[ ${#FAILED_EXECUTIONS[@]} -gt 0 ]]; then
        error "Some workflows failed during batch execution"
        exit 1
    fi
}

# Show help
show_help() {
    cat << EOF
Usage: $0 [workflows_file]

Execute workflows in batch from a file.

Workflows file format (one per line):
workflow_id:{"input":"data"}
user-onboarding:{"email":"user@example.com","name":"User Name"}
payment-processing:{"amount":99.99,"currency":"USD"}

Options:
    BATCH_SIZE=N            Process N workflows at a time (default: 5)
    PARALLEL_EXECUTION=true Execute workflows in parallel (default: false)

Examples:
    $0 workflows.txt
    BATCH_SIZE=10 PARALLEL_EXECUTION=true $0 workflows.txt
EOF
}

# Parse arguments
case "${1:-}" in
    -h|--help)
        show_help
        exit 0
        ;;
esac

main "$@"
```

## Utility Scripts

### Configuration Management Script

```bash
#!/bin/bash
# config-manager.sh - Manage CLI configurations across environments

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CONFIG_TEMPLATES_DIR="${SCRIPT_DIR}/config-templates"

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"; }
error() { log "ERROR: $*" >&2; }
info() { log "INFO: $*"; }

# Initialize configuration templates
init_templates() {
    info "Initializing configuration templates"
    mkdir -p "$CONFIG_TEMPLATES_DIR"
    
    # Development template
    cat > "$CONFIG_TEMPLATES_DIR/development.json" << 'EOF'
{
  "api_url": "https://dev-api.tolstoy.com",
  "timeout": "120s",
  "output_format": "table",
  "settings": {
    "verbose": true,
    "confirm_destructive": false,
    "color_output": true
  }
}
EOF
    
    # Staging template
    cat > "$CONFIG_TEMPLATES_DIR/staging.json" << 'EOF'
{
  "api_url": "https://staging-api.tolstoy.com", 
  "timeout": "60s",
  "output_format": "json",
  "settings": {
    "verbose": false,
    "confirm_destructive": false,
    "color_output": true
  }
}
EOF
    
    # Production template
    cat > "$CONFIG_TEMPLATES_DIR/production.json" << 'EOF'
{
  "api_url": "https://api.tolstoy.com",
  "timeout": "30s", 
  "output_format": "table",
  "settings": {
    "verbose": false,
    "confirm_destructive": true,
    "color_output": true
  }
}
EOF
    
    info "Configuration templates created in $CONFIG_TEMPLATES_DIR"
}

# Setup user profile
setup_profile() {
    local environment="$1"
    local user_id="$2"
    local org_id="$3"
    
    info "Setting up $environment profile for user $user_id"
    
    local template_file="$CONFIG_TEMPLATES_DIR/$environment.json"
    if [[ ! -f "$template_file" ]]; then
        error "Template not found: $template_file"
        return 1
    fi
    
    # Read template values
    local api_url timeout output_format
    api_url=$(jq -r '.api_url' "$template_file")
    timeout=$(jq -r '.timeout' "$template_file") 
    output_format=$(jq -r '.output_format' "$template_file")
    
    # Create profile
    tolstoy config add "$environment" \
        --api-url "$api_url" \
        --org-id "$org_id" \
        --user-id "$user_id" \
        --timeout "$timeout" \
        --output-format "$output_format" \
        --non-interactive
    
    # Apply additional settings
    local verbose confirm_destructive color_output
    verbose=$(jq -r '.settings.verbose' "$template_file")
    confirm_destructive=$(jq -r '.settings.confirm_destructive' "$template_file")
    color_output=$(jq -r '.settings.color_output' "$template_file")
    
    tolstoy config set verbose "$verbose" --profile "$environment"
    tolstoy config set confirm-destructive "$confirm_destructive" --profile "$environment"
    tolstoy config set color-output "$color_output" --profile "$environment"
    
    info "✅ Profile $environment configured successfully"
}

# Validate all profiles
validate_profiles() {
    info "Validating all profiles"
    
    local profiles
    profiles=$(tolstoy config list --json | jq -r '.profiles[].name')
    
    local failed_profiles=()
    
    for profile in $profiles; do
        info "Testing profile: $profile"
        
        if tolstoy config test --profile "$profile" --timeout 10s; then
            info "✅ $profile: OK"
        else
            error "❌ $profile: FAILED"
            failed_profiles+=("$profile")
        fi
    done
    
    if [[ ${#failed_profiles[@]} -gt 0 ]]; then
        error "Failed profiles: ${failed_profiles[*]}"
        return 1
    fi
    
    info "All profiles validated successfully"
}

# Backup configurations
backup_config() {
    local backup_dir="./config-backup-$(date +%Y%m%d-%H%M%S)"
    
    info "Creating configuration backup: $backup_dir"
    mkdir -p "$backup_dir"
    
    # Export all profiles
    tolstoy config export --all > "$backup_dir/all-profiles.json"
    
    # Export individual profiles
    local profiles
    profiles=$(tolstoy config list --json | jq -r '.profiles[].name')
    
    for profile in $profiles; do
        tolstoy config export --profile "$profile" > "$backup_dir/$profile.json"
    done
    
    info "Configuration backup created: $backup_dir"
    echo "$backup_dir"
}

# Restore configurations
restore_config() {
    local backup_file="$1"
    
    if [[ ! -f "$backup_file" ]]; then
        error "Backup file not found: $backup_file"
        return 1
    fi
    
    info "Restoring configuration from: $backup_file"
    
    # Create backup of current config first
    local current_backup
    current_backup=$(backup_config)
    info "Current configuration backed up to: $current_backup"
    
    # Restore from backup
    if tolstoy config import "$backup_file"; then
        info "✅ Configuration restored successfully"
        validate_profiles
    else
        error "❌ Configuration restore failed"
        return 1
    fi
}

# Interactive setup wizard
setup_wizard() {
    info "Starting configuration setup wizard"
    
    # Get user information
    read -p "Enter your user ID: " user_id
    read -p "Enter your organization ID: " org_id
    
    # Get environments to set up
    echo "Select environments to configure:"
    echo "1) Development only"
    echo "2) Development + Staging"
    echo "3) All environments (Dev + Staging + Production)"
    read -p "Choice (1-3): " env_choice
    
    local environments=()
    case "$env_choice" in
        1) environments=("development") ;;
        2) environments=("development" "staging") ;;
        3) environments=("development" "staging" "production") ;;
        *) error "Invalid choice"; return 1 ;;
    esac
    
    # Set up profiles
    for env in "${environments[@]}"; do
        setup_profile "$env" "$user_id" "$org_id"
    done
    
    # Set default profile
    tolstoy config use development
    
    info "🎉 Configuration setup completed!"
    info "Default profile set to: development"
    info "Available profiles: ${environments[*]}"
}

# Show help
show_help() {
    cat << EOF
Usage: $0 <command> [arguments]

Commands:
    init                          Initialize configuration templates
    setup <env> <user_id> <org_id>  Set up specific environment profile  
    wizard                        Interactive setup wizard
    validate                      Validate all profiles
    backup                        Backup current configuration
    restore <backup_file>         Restore configuration from backup
    
Examples:
    $0 init
    $0 wizard
    $0 setup development user_123 org_456
    $0 validate
    $0 backup
    $0 restore ./config-backup/all-profiles.json
EOF
}

# Main function
main() {
    local command="${1:-}"
    
    case "$command" in
        init)
            init_templates
            ;;
        setup)
            if [[ $# -lt 4 ]]; then
                error "Usage: $0 setup <environment> <user_id> <org_id>"
                exit 1
            fi
            setup_profile "$2" "$3" "$4"
            ;;
        wizard)
            setup_wizard
            ;;
        validate)
            validate_profiles
            ;;
        backup)
            backup_config
            ;;
        restore)
            if [[ $# -lt 2 ]]; then
                error "Usage: $0 restore <backup_file>"
                exit 1
            fi
            restore_config "$2"
            ;;
        -h|--help|help)
            show_help
            ;;
        *)
            error "Unknown command: $command"
            show_help
            exit 1
            ;;
    esac
}

main "$@"
```

## Best Practices for CLI Scripts

### Error Handling

```bash
# Comprehensive error handling template
set -euo pipefail  # Exit on error, undefined vars, pipe failures

# Custom error handler
error_handler() {
    local line_number=$1
    local bash_command="$2"
    local exit_code=$3
    
    error "Script failed at line $line_number: $bash_command (exit code: $exit_code)"
    
    # Cleanup function
    cleanup_on_error
    
    exit "$exit_code"
}

# Set error trap
trap 'error_handler $LINENO "$BASH_COMMAND" $?' ERR

# Cleanup function
cleanup_on_error() {
    # Remove temporary files
    rm -f /tmp/tolstoy-script-*
    
    # Reset any changes if needed
    # tolstoy config use previous_profile
    
    info "Cleanup completed"
}
```

### Logging and Output

```bash
# Advanced logging setup
LOG_LEVEL="${LOG_LEVEL:-INFO}"
LOG_FILE="${LOG_FILE:-/tmp/$(basename "$0")-$(date +%Y%m%d-%H%M%S).log}"

# Logging functions with levels
debug() { [[ "$LOG_LEVEL" =~ ^(DEBUG)$ ]] && log "DEBUG: $*"; }
info() { [[ "$LOG_LEVEL" =~ ^(DEBUG|INFO)$ ]] && log "INFO: $*"; }
warn() { [[ "$LOG_LEVEL" =~ ^(DEBUG|INFO|WARN)$ ]] && log "WARN: $*"; }
error() { log "ERROR: $*" >&2; }

log() { echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*" | tee -a "$LOG_FILE"; }

# Progress indicator
show_progress() {
    local current=$1
    local total=$2
    local message="$3"
    
    local percent=$((current * 100 / total))
    local filled=$((percent / 2))
    local empty=$((50 - filled))
    
    printf "\r%s [%s%s] %d%% (%d/%d)" \
        "$message" \
        "$(printf "%*s" $filled | tr ' ' '=')" \
        "$(printf "%*s" $empty)" \
        "$percent" "$current" "$total"
    
    [[ $current -eq $total ]] && echo
}
```

### Configuration Validation

```bash
# Script configuration validation
validate_script_config() {
    local errors=()
    
    # Check required environment variables
    [[ -z "${TOLSTOY_ORG_ID:-}" ]] && errors+=("TOLSTOY_ORG_ID not set")
    [[ -z "${TOLSTOY_USER_ID:-}" ]] && errors+=("TOLSTOY_USER_ID not set")
    
    # Check file permissions
    [[ ! -r "$WORKFLOWS_DIR" ]] && errors+=("Cannot read workflows directory: $WORKFLOWS_DIR")
    [[ ! -w "$BACKUP_DIR" ]] && errors+=("Cannot write to backup directory: $BACKUP_DIR")
    
    # Check CLI connectivity
    if ! tolstoy config test --timeout 10s >/dev/null 2>&1; then
        errors+=("Tolstoy CLI connectivity test failed")
    fi
    
    if [[ ${#errors[@]} -gt 0 ]]; then
        error "Configuration validation failed:"
        printf '%s\n' "${errors[@]}" >&2
        return 1
    fi
    
    info "Configuration validation passed"
}
```

## Next Steps

You now have a comprehensive toolkit of automation scripts. Here's how to continue:

<CardGroup cols={2}>
  <Card title="CI/CD Integration" icon="infinity" href="/cli/guides/ci-cd-integration">
    Integrate these scripts into your CI/CD pipelines
  </Card>
  <Card title="Monitoring Setup" icon="chart-line" href="/cli/guides/monitoring-setup">
    Set up comprehensive monitoring and alerting
  </Card>
</CardGroup>

<CardGroup cols={2}>
  <Card title="Team Automation" icon="users" href="/cli/guides/team-automation">
    Scale automation across your team
  </Card>
  <Card title="Security Practices" icon="shield" href="/cli/guides/security-practices">
    Implement security best practices in your scripts
  </Card>
</CardGroup>

---

*These automation scripts provide a solid foundation for managing Tolstoy workflows at scale. Customize them for your specific needs and integrate them into your operational processes.*