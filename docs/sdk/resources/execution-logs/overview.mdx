---
title: "Execution Logs SDK Overview"
description: "Complete guide to accessing, analyzing, and monitoring execution logs with the Tolstoy TypeScript SDK."
---

# Execution Logs SDK Overview

The Execution Logs SDK provides comprehensive functionality for accessing, analyzing, and monitoring execution logs from flows, actions, and other operations within your Tolstoy applications. This powerful logging system enables debugging, monitoring, compliance, and performance optimization.

## Quick Start

```typescript
import { TolstoyClient } from '@joosuhail/tolstoy-sdk';

const client = new TolstoyClient({
  orgId: process.env.TOLSTOY_ORG_ID!,
  userId: process.env.TOLSTOY_USER_ID!
});

// Get recent execution logs
const logs = await client.executionLogs.list({
  limit: 50,
  orderBy: 'timestamp',
  order: 'desc'
});

// Get logs for a specific execution
const executionLogs = await client.executionLogs.getByExecution('execution_abc123');

// Stream real-time logs
for await (const logEntry of client.executionLogs.stream()) {
  console.log(`[${logEntry.timestamp}] ${logEntry.level}: ${logEntry.message}`);
}
```

## Available Methods

### Log Retrieval

| Method | Description | Returns |
|--------|-------------|---------|
| `list(options?)` | List logs with filtering and pagination | `Promise<LogEntry[]>` |
| `get(logId)` | Get a specific log entry | `Promise<LogEntry>` |
| `getByExecution(executionId, options?)` | Get logs for specific execution | `Promise<LogEntry[]>` |
| `getByFlow(flowId, options?)` | Get logs for all executions of a flow | `Promise<LogEntry[]>` |
| `getByAction(actionId, options?)` | Get logs for specific action | `Promise<LogEntry[]>` |
| `getByDateRange(startDate, endDate, options?)` | Get logs within date range | `Promise<LogEntry[]>` |

### Real-time Monitoring

| Method | Description | Returns |
|--------|-------------|---------|
| `stream(options?)` | Stream real-time logs | `AsyncIterator<LogEntry>` |
| `streamByExecution(executionId)` | Stream logs for specific execution | `AsyncIterator<LogEntry>` |
| `subscribe(filter, callback)` | Subscribe to log events | `Promise<Subscription>` |
| `unsubscribe(subscriptionId)` | Unsubscribe from log events | `Promise<void>` |

### Log Analysis

| Method | Description | Returns |
|--------|-------------|---------|
| `search(query, options?)` | Search logs by content | `Promise<SearchResult>` |
| `aggregate(aggregation, options?)` | Aggregate log data | `Promise<AggregationResult>` |
| `getMetrics(timeframe, options?)` | Get log metrics and statistics | `Promise<LogMetrics>` |
| `getErrorSummary(options?)` | Get error patterns and summaries | `Promise<ErrorSummary>` |

### Log Management

| Method | Description | Returns |
|--------|-------------|---------|
| `export(options)` | Export logs to various formats | `Promise<ExportResult>` |
| `archive(options)` | Archive old logs | `Promise<ArchiveResult>` |
| `purge(options)` | Delete logs based on criteria | `Promise<PurgeResult>` |

## Core Types

### Log Entry Structure

```typescript
interface LogEntry {
  id: string;
  timestamp: string;
  level: LogLevel;
  message: string;
  
  // Context information
  executionId?: string;
  flowId?: string;
  actionId?: string;
  stepKey?: string;
  
  // Structured data
  data?: Record<string, any>;
  metadata?: LogMetadata;
  
  // Error information
  error?: ErrorInfo;
  
  // Performance data
  duration?: number;
  memoryUsage?: number;
  
  // Source information
  source: LogSource;
  component: string;
  
  // Tags and labels
  tags: string[];
  labels?: Record<string, string>;
}

type LogLevel = 'debug' | 'info' | 'warn' | 'error' | 'fatal';

interface LogMetadata {
  orgId: string;
  userId: string;
  environment: string;
  version: string;
  region: string;
  instanceId: string;
}

interface ErrorInfo {
  name: string;
  message: string;
  stack?: string;
  code?: string;
  details?: Record<string, any>;
}

interface LogSource {
  type: 'flow' | 'action' | 'webhook' | 'api' | 'system';
  id: string;
  name: string;
}
```

### Search and Filtering

```typescript
interface LogQuery {
  // Time filtering
  startTime?: string;
  endTime?: string;
  timeframe?: '1h' | '4h' | '12h' | '1d' | '7d' | '30d';
  
  // Content filtering
  search?: string;
  level?: LogLevel | LogLevel[];
  message?: string;
  
  // Context filtering
  executionId?: string;
  flowId?: string;
  actionId?: string;
  component?: string;
  source?: string;
  
  // Tag filtering
  tags?: string[];
  labels?: Record<string, string>;
  
  // Error filtering
  hasError?: boolean;
  errorType?: string;
  
  // Pagination
  limit?: number;
  offset?: number;
  orderBy?: 'timestamp' | 'level' | 'duration';
  order?: 'asc' | 'desc';
}

interface SearchResult {
  entries: LogEntry[];
  total: number;
  query: string;
  highlights: SearchHighlight[];
  facets: SearchFacet[];
}

interface SearchHighlight {
  field: string;
  matches: string[];
  context: string;
}

interface SearchFacet {
  field: string;
  values: Array<{
    value: string;
    count: number;
  }>;
}
```

## Basic Usage Examples

### Retrieving and Filtering Logs

<CodeGroup>
```typescript Basic Log Retrieval
// Get recent logs
const recentLogs = await client.executionLogs.list({
  limit: 100,
  orderBy: 'timestamp',
  order: 'desc'
});

console.log(`Retrieved ${recentLogs.length} log entries`);
recentLogs.forEach(log => {
  console.log(`[${log.timestamp}] ${log.level}: ${log.message}`);
});
```

```typescript Filter by Level and Time
// Get error logs from the last 24 hours
const errorLogs = await client.executionLogs.list({
  level: 'error',
  timeframe: '1d',
  orderBy: 'timestamp',
  order: 'desc'
});

console.log(`Found ${errorLogs.length} errors in the last 24 hours`);

// Get logs for specific execution
const executionLogs = await client.executionLogs.getByExecution('execution_abc123', {
  includeDebug: true,
  orderBy: 'timestamp',
  order: 'asc'
});
```

```typescript Advanced Filtering
// Complex filter with multiple criteria
const filteredLogs = await client.executionLogs.list({
  startTime: '2024-01-01T00:00:00Z',
  endTime: '2024-01-01T23:59:59Z',
  level: ['warn', 'error'],
  flowId: 'flow_user_onboarding',
  tags: ['production', 'critical'],
  hasError: true,
  limit: 500
});

// Filter by component and source
const apiLogs = await client.executionLogs.list({
  component: 'api-gateway',
  source: 'webhook',
  timeframe: '4h',
  labels: {
    environment: 'production',
    version: 'v1.2.3'
  }
});
```
</CodeGroup>

### Real-time Log Monitoring

<CodeGroup>
```typescript Stream All Logs
// Stream real-time logs with filtering
const logStream = client.executionLogs.stream({
  level: ['warn', 'error', 'fatal'],
  source: 'flow'
});

console.log('üî¥ Monitoring critical logs...');

for await (const logEntry of logStream) {
  const emoji = {
    'warn': '‚ö†Ô∏è',
    'error': '‚ùå',
    'fatal': 'üíÄ'
  }[logEntry.level] || '‚ÑπÔ∏è';
  
  console.log(`${emoji} [${logEntry.timestamp}] ${logEntry.component}: ${logEntry.message}`);
  
  if (logEntry.error) {
    console.log(`   Error: ${logEntry.error.name}: ${logEntry.error.message}`);
  }
  
  if (logEntry.executionId) {
    console.log(`   Execution: ${logEntry.executionId}`);
  }
}
```

```typescript Monitor Specific Execution
// Monitor logs for a specific execution in real-time
async function monitorExecution(executionId: string) {
  console.log(`üîç Monitoring execution: ${executionId}`);
  
  const logStream = client.executionLogs.streamByExecution(executionId);
  const executionLogs: LogEntry[] = [];
  
  try {
    for await (const logEntry of logStream) {
      executionLogs.push(logEntry);
      
      const timestamp = new Date(logEntry.timestamp).toLocaleTimeString();
      const levelColor = {
        'debug': '\x1b[37m',    // white
        'info': '\x1b[36m',     // cyan
        'warn': '\x1b[33m',     // yellow
        'error': '\x1b[31m',    // red
        'fatal': '\x1b[35m'     // magenta
      }[logEntry.level] || '\x1b[0m';
      
      console.log(`${levelColor}[${timestamp}] ${logEntry.level.toUpperCase()}: ${logEntry.message}\x1b[0m`);
      
      if (logEntry.data) {
        console.log('  Data:', JSON.stringify(logEntry.data, null, 2));
      }
      
      if (logEntry.error) {
        console.log(`  Error: ${logEntry.error.message}`);
        if (logEntry.error.stack) {
          console.log('  Stack:', logEntry.error.stack.split('\n').slice(0, 3).join('\n'));
        }
      }
      
      // Check if execution is complete
      if (logEntry.message.includes('execution completed') || 
          logEntry.message.includes('execution failed')) {
        console.log('üèÅ Execution finished');
        break;
      }
    }
  } catch (error) {
    console.error('Stream error:', error);
  }
  
  return executionLogs;
}

// Usage
const logs = await monitorExecution('execution_abc123');
console.log(`Collected ${logs.length} log entries`);
```

```typescript Subscribe to Log Events
// Subscribe to specific log patterns
const subscription = await client.executionLogs.subscribe({
  level: 'error',
  flowId: 'critical_business_flow',
  tags: ['production']
}, async (logEntry) => {
  console.log('üö® CRITICAL ERROR DETECTED:', logEntry.message);
  
  // Send alert to monitoring system
  await sendSlackAlert({
    channel: '#alerts',
    message: `Critical error in ${logEntry.flowId}: ${logEntry.message}`,
    executionId: logEntry.executionId,
    timestamp: logEntry.timestamp
  });
  
  // Trigger incident response
  if (logEntry.error?.code === 'PAYMENT_FAILURE') {
    await triggerIncidentResponse('payment-system-error', logEntry);
  }
});

console.log('‚úÖ Subscribed to critical error alerts');

// Clean up subscription after 1 hour
setTimeout(async () => {
  await client.executionLogs.unsubscribe(subscription.id);
  console.log('üîï Unsubscribed from alerts');
}, 3600000);

async function sendSlackAlert(alert: any) {
  // Implementation depends on your Slack integration
  console.log('Sending Slack alert:', alert);
}

async function triggerIncidentResponse(type: string, logEntry: LogEntry) {
  // Implementation depends on your incident response system
  console.log('Triggering incident response:', type, logEntry.id);
}
```
</CodeGroup>

### Log Search and Analysis

<CodeGroup>
```typescript Text Search
// Search logs by content
const searchResults = await client.executionLogs.search('payment failed', {
  timeframe: '7d',
  level: ['warn', 'error'],
  includeContext: true,
  highlightMatches: true
});

console.log(`Found ${searchResults.total} matching entries`);

searchResults.entries.forEach((entry, index) => {
  console.log(`\n--- Result ${index + 1} ---`);
  console.log(`Timestamp: ${entry.timestamp}`);
  console.log(`Level: ${entry.level}`);
  console.log(`Message: ${entry.message}`);
  
  if (entry.executionId) {
    console.log(`Execution: ${entry.executionId}`);
  }
});

// Show search facets
console.log('\n--- Facets ---');
searchResults.facets.forEach(facet => {
  console.log(`${facet.field}:`);
  facet.values.forEach(value => {
    console.log(`  ${value.value}: ${value.count}`);
  });
});
```

```typescript Advanced Search Patterns
// Complex search with multiple criteria
const complexSearch = await client.executionLogs.search(
  'timeout OR "connection refused" OR "rate limit"', 
  {
    timeframe: '1d',
    flowId: ['user_onboarding', 'payment_processing'],
    component: 'external-api',
    includeStackTraces: true
  }
);

// Search for performance issues
const performanceIssues = await client.executionLogs.search(
  'duration > 5000 OR "slow query" OR "high memory"',
  {
    timeframe: '4h',
    tags: ['performance'],
    orderBy: 'duration',
    order: 'desc'
  }
);

// Search for security events
const securityEvents = await client.executionLogs.search(
  '"authentication failed" OR "unauthorized" OR "suspicious activity"',
  {
    timeframe: '24h',
    level: ['warn', 'error'],
    labels: {
      environment: 'production'
    }
  }
);
```

```typescript Log Aggregation
// Aggregate error counts by flow
const errorsByFlow = await client.executionLogs.aggregate({
  type: 'count',
  groupBy: 'flowId',
  filter: {
    level: 'error',
    timeframe: '7d'
  }
});

console.log('Error counts by flow:');
Object.entries(errorsByFlow.results).forEach(([flowId, count]) => {
  console.log(`  ${flowId}: ${count} errors`);
});

// Aggregate response times by action
const responseTimesByAction = await client.executionLogs.aggregate({
  type: 'avg',
  field: 'duration',
  groupBy: 'actionId',
  filter: {
    hasError: false,
    timeframe: '1d'
  }
});

// Get hourly error rates
const hourlyErrors = await client.executionLogs.aggregate({
  type: 'count',
  groupBy: 'hour',
  filter: {
    level: ['error', 'fatal'],
    timeframe: '24h'
  }
});

console.log('Hourly error distribution:');
hourlyErrors.timeSeries.forEach(point => {
  console.log(`  ${point.time}: ${point.value} errors`);
});
```
</CodeGroup>

## Advanced Usage Patterns

### Log Analytics Dashboard

```typescript
interface DashboardMetrics {
  totalLogs: number;
  errorRate: number;
  averageResponseTime: number;
  topErrors: ErrorPattern[];
  performanceMetrics: PerformanceMetric[];
  activityTrends: ActivityTrend[];
}

interface ErrorPattern {
  message: string;
  count: number;
  affectedFlows: string[];
  lastOccurrence: string;
}

interface PerformanceMetric {
  component: string;
  averageDuration: number;
  p95Duration: number;
  throughput: number;
}

interface ActivityTrend {
  timestamp: string;
  totalExecutions: number;
  successfulExecutions: number;
  failedExecutions: number;
}

class LogAnalyticsDashboard {
  constructor(private client: TolstoyClient) {}
  
  async generateDashboard(timeframe: string = '24h'): Promise<DashboardMetrics> {
    console.log(`üìä Generating analytics dashboard for ${timeframe}...`);
    
    // Run multiple queries in parallel
    const [
      totalLogsResult,
      errorMetrics,
      performanceData,
      errorPatterns,
      activityData
    ] = await Promise.all([
      this.getTotalLogCount(timeframe),
      this.getErrorMetrics(timeframe),
      this.getPerformanceMetrics(timeframe),
      this.getTopErrorPatterns(timeframe),
      this.getActivityTrends(timeframe)
    ]);
    
    return {
      totalLogs: totalLogsResult.count,
      errorRate: errorMetrics.errorRate,
      averageResponseTime: performanceData.averageResponseTime,
      topErrors: errorPatterns,
      performanceMetrics: performanceData.metrics,
      activityTrends: activityData
    };
  }
  
  private async getTotalLogCount(timeframe: string) {
    const result = await this.client.executionLogs.aggregate({
      type: 'count',
      filter: { timeframe }
    });
    
    return { count: result.total };
  }
  
  private async getErrorMetrics(timeframe: string) {
    const [totalLogs, errorLogs] = await Promise.all([
      this.client.executionLogs.aggregate({
        type: 'count',
        filter: { timeframe }
      }),
      this.client.executionLogs.aggregate({
        type: 'count',
        filter: {
          timeframe,
          level: ['error', 'fatal']
        }
      })
    ]);
    
    const errorRate = totalLogs.total > 0 
      ? (errorLogs.total / totalLogs.total) * 100 
      : 0;
    
    return { errorRate };
  }
  
  private async getPerformanceMetrics(timeframe: string) {
    const performanceAgg = await this.client.executionLogs.aggregate({
      type: 'stats',
      field: 'duration',
      groupBy: 'component',
      filter: {
        timeframe,
        hasError: false
      }
    });
    
    const metrics: PerformanceMetric[] = Object.entries(performanceAgg.groups).map(([component, stats]: [string, any]) => ({
      component,
      averageDuration: stats.avg,
      p95Duration: stats.percentiles?.p95 || 0,
      throughput: stats.count
    }));
    
    const overallAvg = Object.values(performanceAgg.groups)
      .reduce((sum: number, stats: any) => sum + stats.avg, 0) / Object.keys(performanceAgg.groups).length;
    
    return {
      averageResponseTime: overallAvg,
      metrics
    };
  }
  
  private async getTopErrorPatterns(timeframe: string): Promise<ErrorPattern[]> {
    const errorAgg = await this.client.executionLogs.aggregate({
      type: 'count',
      groupBy: ['message', 'flowId'],
      filter: {
        timeframe,
        level: ['error', 'fatal']
      },
      limit: 10
    });
    
    const patterns = new Map<string, ErrorPattern>();
    
    Object.entries(errorAgg.groups).forEach(([key, data]: [string, any]) => {
      const [message, flowId] = key.split('|');
      
      if (patterns.has(message)) {
        const pattern = patterns.get(message)!;
        pattern.count += data.count;
        if (!pattern.affectedFlows.includes(flowId)) {
          pattern.affectedFlows.push(flowId);
        }
        if (data.lastOccurrence > pattern.lastOccurrence) {
          pattern.lastOccurrence = data.lastOccurrence;
        }
      } else {
        patterns.set(message, {
          message,
          count: data.count,
          affectedFlows: [flowId],
          lastOccurrence: data.lastOccurrence
        });
      }
    });
    
    return Array.from(patterns.values())
      .sort((a, b) => b.count - a.count)
      .slice(0, 10);
  }
  
  private async getActivityTrends(timeframe: string): Promise<ActivityTrend[]> {
    const activityAgg = await this.client.executionLogs.aggregate({
      type: 'count',
      groupBy: ['hour', 'level'],
      filter: { timeframe }
    });
    
    const trends = new Map<string, ActivityTrend>();
    
    Object.entries(activityAgg.timeSeries || {}).forEach(([timestamp, data]: [string, any]) => {
      if (!trends.has(timestamp)) {
        trends.set(timestamp, {
          timestamp,
          totalExecutions: 0,
          successfulExecutions: 0,
          failedExecutions: 0
        });
      }
      
      const trend = trends.get(timestamp)!;
      
      Object.entries(data.levels || {}).forEach(([level, count]: [string, any]) => {
        trend.totalExecutions += count;
        
        if (['error', 'fatal'].includes(level)) {
          trend.failedExecutions += count;
        } else {
          trend.successfulExecutions += count;
        }
      });
    });
    
    return Array.from(trends.values()).sort((a, b) => 
      new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
    );
  }
  
  async printDashboard(timeframe: string = '24h') {
    const metrics = await this.generateDashboard(timeframe);
    
    console.log('\n' + '='.repeat(60));
    console.log(`üìä LOG ANALYTICS DASHBOARD (${timeframe})`);
    console.log('='.repeat(60));
    
    // Overview
    console.log('\nüìà OVERVIEW');
    console.log(`Total Logs: ${metrics.totalLogs.toLocaleString()}`);
    console.log(`Error Rate: ${metrics.errorRate.toFixed(2)}%`);
    console.log(`Avg Response Time: ${metrics.averageResponseTime.toFixed(0)}ms`);
    
    // Top Errors
    console.log('\n‚ùå TOP ERROR PATTERNS');
    metrics.topErrors.forEach((error, index) => {
      console.log(`${index + 1}. ${error.message.slice(0, 60)}...`);
      console.log(`   Count: ${error.count} | Flows: ${error.affectedFlows.length} | Last: ${error.lastOccurrence}`);
    });
    
    // Performance
    console.log('\n‚ö° PERFORMANCE METRICS');
    metrics.performanceMetrics.forEach(metric => {
      console.log(`${metric.component}:`);
      console.log(`   Avg: ${metric.averageDuration.toFixed(0)}ms | P95: ${metric.p95Duration.toFixed(0)}ms | Throughput: ${metric.throughput}`);
    });
    
    // Activity Trends (last 6 hours)
    console.log('\nüìä ACTIVITY TRENDS (Last 6 Hours)');
    metrics.activityTrends.slice(-6).forEach(trend => {
      const timestamp = new Date(trend.timestamp).toLocaleTimeString();
      const successRate = trend.totalExecutions > 0 
        ? ((trend.successfulExecutions / trend.totalExecutions) * 100).toFixed(1) 
        : '0.0';
      
      console.log(`${timestamp}: ${trend.totalExecutions} total (${successRate}% success)`);
    });
    
    console.log('\n' + '='.repeat(60));
  }
  
  async exportDashboard(timeframe: string = '24h', format: 'json' | 'csv' = 'json') {
    const metrics = await this.generateDashboard(timeframe);
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    
    if (format === 'json') {
      const filename = `dashboard-${timeframe}-${timestamp}.json`;
      const fs = require('fs').promises;
      await fs.writeFile(filename, JSON.stringify(metrics, null, 2));
      console.log(`üìÅ Dashboard exported to ${filename}`);
    } else if (format === 'csv') {
      // Convert to CSV format
      const csvData = this.convertToCSV(metrics);
      const filename = `dashboard-${timeframe}-${timestamp}.csv`;
      const fs = require('fs').promises;
      await fs.writeFile(filename, csvData);
      console.log(`üìÅ Dashboard exported to ${filename}`);
    }
  }
  
  private convertToCSV(metrics: DashboardMetrics): string {
    const rows = [
      ['Metric', 'Value', 'Details'],
      ['Total Logs', metrics.totalLogs.toString(), ''],
      ['Error Rate', `${metrics.errorRate.toFixed(2)}%`, ''],
      ['Average Response Time', `${metrics.averageResponseTime.toFixed(0)}ms`, ''],
      ['', '', ''], // Empty row
      ['Top Errors', '', ''],
    ];
    
    metrics.topErrors.forEach((error, index) => {
      rows.push([
        `Error ${index + 1}`,
        error.count.toString(),
        error.message.slice(0, 100)
      ]);
    });
    
    return rows.map(row => row.map(cell => `"${cell}"`).join(',')).join('\n');
  }
}

// Usage
const dashboard = new LogAnalyticsDashboard(client);

// Generate and display dashboard
await dashboard.printDashboard('24h');

// Export dashboard data
await dashboard.exportDashboard('24h', 'json');

// Schedule periodic dashboard updates
setInterval(async () => {
  console.log('\nüîÑ Updating dashboard...');
  await dashboard.printDashboard('1h');
}, 300000); // Update every 5 minutes
```

### Automated Log Monitoring and Alerting

```typescript
interface AlertRule {
  name: string;
  description: string;
  condition: AlertCondition;
  actions: AlertAction[];
  cooldown?: number; // Minimum time between alerts (ms)
  enabled: boolean;
}

interface AlertCondition {
  type: 'threshold' | 'pattern' | 'anomaly' | 'absence';
  timeWindow: string;
  threshold?: number;
  pattern?: string;
  field?: string;
  aggregation?: 'count' | 'rate' | 'avg' | 'max';
  comparison?: '>' | '<' | '=' | '!=' | '>=' | '<=';
}

interface AlertAction {
  type: 'email' | 'slack' | 'webhook' | 'pagerduty';
  config: Record<string, any>;
}

class LogMonitoringSystem {
  private alertRules: Map<string, AlertRule> = new Map();
  private alertHistory: Map<string, number> = new Map(); // Last alert time
  private isRunning = false;
  
  constructor(private client: TolstoyClient) {}
  
  addAlertRule(rule: AlertRule): void {
    this.alertRules.set(rule.name, rule);
    console.log(`‚úÖ Added alert rule: ${rule.name}`);
  }
  
  removeAlertRule(ruleName: string): void {
    this.alertRules.delete(ruleName);
    console.log(`üóëÔ∏è Removed alert rule: ${ruleName}`);
  }
  
  async startMonitoring(): Promise<void> {
    if (this.isRunning) {
      console.log('‚ö†Ô∏è Monitoring is already running');
      return;
    }
    
    this.isRunning = true;
    console.log('üöÄ Starting log monitoring system...');
    
    // Check rules every 30 seconds
    const monitoringInterval = setInterval(async () => {
      if (!this.isRunning) {
        clearInterval(monitoringInterval);
        return;
      }
      
      try {
        await this.checkAlertRules();
      } catch (error) {
        console.error('Error checking alert rules:', error);
      }
    }, 30000);
    
    console.log('‚úÖ Log monitoring system started');
  }
  
  stopMonitoring(): void {
    this.isRunning = false;
    console.log('üõë Log monitoring system stopped');
  }
  
  private async checkAlertRules(): Promise<void> {
    const activeRules = Array.from(this.alertRules.values()).filter(rule => rule.enabled);
    
    for (const rule of activeRules) {
      try {
        const shouldAlert = await this.evaluateRule(rule);
        
        if (shouldAlert) {
          const lastAlert = this.alertHistory.get(rule.name) || 0;
          const cooldownPeriod = rule.cooldown || 300000; // 5 minutes default
          
          if (Date.now() - lastAlert > cooldownPeriod) {
            await this.triggerAlert(rule);
            this.alertHistory.set(rule.name, Date.now());
          }
        }
      } catch (error) {
        console.error(`Error evaluating rule ${rule.name}:`, error);
      }
    }
  }
  
  private async evaluateRule(rule: AlertRule): Promise<boolean> {
    const { condition } = rule;
    
    switch (condition.type) {
      case 'threshold':
        return await this.evaluateThresholdCondition(condition);
      case 'pattern':
        return await this.evaluatePatternCondition(condition);
      case 'anomaly':
        return await this.evaluateAnomalyCondition(condition);
      case 'absence':
        return await this.evaluateAbsenceCondition(condition);
      default:
        return false;
    }
  }
  
  private async evaluateThresholdCondition(condition: AlertCondition): Promise<boolean> {
    const aggregation = await this.client.executionLogs.aggregate({
      type: condition.aggregation || 'count',
      field: condition.field,
      filter: {
        timeframe: condition.timeWindow,
        level: ['error', 'fatal'] // Focus on errors for threshold alerts
      }
    });
    
    const value = condition.aggregation === 'rate' 
      ? aggregation.rate 
      : aggregation.total;
    
    const threshold = condition.threshold || 0;
    
    switch (condition.comparison) {
      case '>': return value > threshold;
      case '<': return value < threshold;
      case '>=': return value >= threshold;
      case '<=': return value <= threshold;
      case '=': return value === threshold;
      case '!=': return value !== threshold;
      default: return false;
    }
  }
  
  private async evaluatePatternCondition(condition: AlertCondition): Promise<boolean> {
    const searchResult = await this.client.executionLogs.search(condition.pattern!, {
      timeframe: condition.timeWindow,
      level: ['warn', 'error', 'fatal']
    });
    
    return searchResult.total > 0;
  }
  
  private async evaluateAnomalyCondition(condition: AlertCondition): Promise<boolean> {
    // Simple anomaly detection based on historical averages
    const currentMetrics = await this.client.executionLogs.getMetrics(condition.timeWindow);
    const historicalMetrics = await this.client.executionLogs.getMetrics('7d'); // 7-day baseline
    
    const currentErrorRate = currentMetrics.errorRate;
    const historicalErrorRate = historicalMetrics.averageErrorRate;
    
    // Alert if current error rate is 2x higher than historical average
    return currentErrorRate > historicalErrorRate * 2;
  }
  
  private async evaluateAbsenceCondition(condition: AlertCondition): Promise<boolean> {
    const logs = await this.client.executionLogs.list({
      search: condition.pattern,
      timeframe: condition.timeWindow,
      limit: 1
    });
    
    return logs.length === 0;
  }
  
  private async triggerAlert(rule: AlertRule): Promise<void> {
    console.log(`üö® ALERT TRIGGERED: ${rule.name}`);
    
    for (const action of rule.actions) {
      try {
        await this.executeAlertAction(action, rule);
      } catch (error) {
        console.error(`Error executing alert action ${action.type}:`, error);
      }
    }
  }
  
  private async executeAlertAction(action: AlertAction, rule: AlertRule): Promise<void> {
    switch (action.type) {
      case 'email':
        await this.sendEmailAlert(action.config, rule);
        break;
      case 'slack':
        await this.sendSlackAlert(action.config, rule);
        break;
      case 'webhook':
        await this.sendWebhookAlert(action.config, rule);
        break;
      case 'pagerduty':
        await this.sendPagerDutyAlert(action.config, rule);
        break;
    }
  }
  
  private async sendEmailAlert(config: any, rule: AlertRule): Promise<void> {
    // Implementation depends on your email service
    console.log(`üìß Sending email alert for rule: ${rule.name}`);
  }
  
  private async sendSlackAlert(config: any, rule: AlertRule): Promise<void> {
    // Implementation depends on your Slack integration
    console.log(`üí¨ Sending Slack alert for rule: ${rule.name}`);
  }
  
  private async sendWebhookAlert(config: any, rule: AlertRule): Promise<void> {
    const response = await fetch(config.url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...config.headers
      },
      body: JSON.stringify({
        rule: rule.name,
        description: rule.description,
        timestamp: new Date().toISOString(),
        severity: config.severity || 'warning'
      })
    });
    
    if (!response.ok) {
      throw new Error(`Webhook alert failed: ${response.statusText}`);
    }
    
    console.log(`üîó Webhook alert sent for rule: ${rule.name}`);
  }
  
  private async sendPagerDutyAlert(config: any, rule: AlertRule): Promise<void> {
    // Implementation depends on your PagerDuty integration
    console.log(`üìü PagerDuty alert sent for rule: ${rule.name}`);
  }
}

// Usage
const monitoring = new LogMonitoringSystem(client);

// Add alert rules
monitoring.addAlertRule({
  name: 'High Error Rate',
  description: 'Error rate exceeds 5% in the last 15 minutes',
  condition: {
    type: 'threshold',
    timeWindow: '15m',
    field: 'level',
    aggregation: 'rate',
    threshold: 5,
    comparison: '>'
  },
  actions: [
    {
      type: 'slack',
      config: {
        channel: '#alerts',
        severity: 'warning'
      }
    },
    {
      type: 'email',
      config: {
        recipients: ['oncall@company.com'],
        priority: 'high'
      }
    }
  ],
  cooldown: 900000, // 15 minutes
  enabled: true
});

monitoring.addAlertRule({
  name: 'Payment Failures',
  description: 'Payment processing errors detected',
  condition: {
    type: 'pattern',
    timeWindow: '5m',
    pattern: 'payment failed OR "transaction declined"'
  },
  actions: [
    {
      type: 'pagerduty',
      config: {
        serviceKey: 'payment-service-key',
        severity: 'critical'
      }
    }
  ],
  cooldown: 300000, // 5 minutes
  enabled: true
});

monitoring.addAlertRule({
  name: 'System Anomaly',
  description: 'Abnormal system behavior detected',
  condition: {
    type: 'anomaly',
    timeWindow: '30m'
  },
  actions: [
    {
      type: 'webhook',
      config: {
        url: 'https://monitoring.company.com/alerts',
        headers: {
          'Authorization': 'Bearer token123'
        },
        severity: 'warning'
      }
    }
  ],
  cooldown: 1800000, // 30 minutes
  enabled: true
});

// Start monitoring
await monitoring.startMonitoring();

// Monitor will run until stopped
// monitoring.stopMonitoring();
```

## Log Export and Archiving

### Export Logs to Various Formats

```typescript
interface ExportOptions {
  format: 'json' | 'csv' | 'tsv' | 'parquet' | 'elasticsearch';
  compression?: 'gzip' | 'bzip2' | 'none';
  destination?: {
    type: 's3' | 'gcs' | 'azure' | 'local';
    config: Record<string, any>;
  };
  filter?: LogQuery;
  includeMetadata?: boolean;
  batchSize?: number;
}

class LogExporter {
  constructor(private client: TolstoyClient) {}
  
  async exportLogs(options: ExportOptions): Promise<ExportResult> {
    console.log(`üì¶ Starting log export (${options.format})...`);
    
    const startTime = Date.now();
    const filter = options.filter || { timeframe: '24h' };
    
    // Get total count for progress tracking
    const totalCount = await this.client.executionLogs.aggregate({
      type: 'count',
      filter
    });
    
    console.log(`üìä Total logs to export: ${totalCount.total}`);
    
    let exportedCount = 0;
    const batchSize = options.batchSize || 1000;
    const batches: any[] = [];
    
    // Export in batches
    for (let offset = 0; offset < totalCount.total; offset += batchSize) {
      const batch = await this.client.executionLogs.list({
        ...filter,
        limit: batchSize,
        offset,
        orderBy: 'timestamp',
        order: 'asc'
      });
      
      batches.push(batch);
      exportedCount += batch.length;
      
      const progress = (exportedCount / totalCount.total) * 100;
      console.log(`üìà Progress: ${progress.toFixed(1)}% (${exportedCount}/${totalCount.total})`);
    }
    
    // Combine all batches
    const allLogs = batches.flat();
    
    // Format data based on export format
    let formattedData: string;
    let filename: string;
    
    const timestamp = new Date().toISOString().split('T')[0];
    
    switch (options.format) {
      case 'json':
        formattedData = JSON.stringify(allLogs, null, 2);
        filename = `logs-export-${timestamp}.json`;
        break;
        
      case 'csv':
        formattedData = this.convertToCSV(allLogs, options.includeMetadata);
        filename = `logs-export-${timestamp}.csv`;
        break;
        
      case 'tsv':
        formattedData = this.convertToTSV(allLogs, options.includeMetadata);
        filename = `logs-export-${timestamp}.tsv`;
        break;
        
      default:
        throw new Error(`Unsupported export format: ${options.format}`);
    }
    
    // Apply compression if requested
    if (options.compression && options.compression !== 'none') {
      formattedData = await this.compressData(formattedData, options.compression);
      filename += `.${options.compression}`;
    }
    
    // Save to destination
    if (options.destination) {
      await this.saveToDestination(formattedData, filename, options.destination);
    } else {
      // Save locally
      const fs = require('fs').promises;
      await fs.writeFile(filename, formattedData);
      console.log(`üíæ Exported to: ${filename}`);
    }
    
    const duration = Date.now() - startTime;
    
    return {
      filename,
      recordCount: allLogs.length,
      fileSize: formattedData.length,
      duration,
      format: options.format,
      compressed: options.compression !== 'none'
    };
  }
  
  private convertToCSV(logs: LogEntry[], includeMetadata = true): string {
    if (logs.length === 0) return '';
    
    const headers = [
      'id', 'timestamp', 'level', 'message', 'executionId', 'flowId', 'actionId',
      'component', 'source', 'duration', 'tags'
    ];
    
    if (includeMetadata) {
      headers.push('metadata', 'error', 'data');
    }
    
    const rows = [headers];
    
    logs.forEach(log => {
      const row = [
        log.id,
        log.timestamp,
        log.level,
        log.message.replace(/"/g, '""'), // Escape quotes
        log.executionId || '',
        log.flowId || '',
        log.actionId || '',
        log.component,
        log.source?.type || '',
        log.duration?.toString() || '',
        log.tags.join(';')
      ];
      
      if (includeMetadata) {
        row.push(
          JSON.stringify(log.metadata || {}),
          JSON.stringify(log.error || {}),
          JSON.stringify(log.data || {})
        );
      }
      
      rows.push(row);
    });
    
    return rows.map(row => 
      row.map(cell => `"${cell}"`).join(',')
    ).join('\n');
  }
  
  private convertToTSV(logs: LogEntry[], includeMetadata = true): string {
    return this.convertToCSV(logs, includeMetadata)
      .split('\n')
      .map(line => line.replace(/","/g, '\t').replace(/^"|"$/g, ''))
      .join('\n');
  }
  
  private async compressData(data: string, compression: string): Promise<string> {
    const zlib = require('zlib');
    const util = require('util');
    
    switch (compression) {
      case 'gzip':
        const gzip = util.promisify(zlib.gzip);
        return await gzip(Buffer.from(data));
        
      case 'bzip2':
        // Note: Node.js doesn't have built-in bzip2, would need external library
        throw new Error('bzip2 compression not implemented');
        
      default:
        throw new Error(`Unsupported compression: ${compression}`);
    }
  }
  
  private async saveToDestination(
    data: string, 
    filename: string, 
    destination: NonNullable<ExportOptions['destination']>
  ): Promise<void> {
    switch (destination.type) {
      case 's3':
        await this.saveToS3(data, filename, destination.config);
        break;
      case 'gcs':
        await this.saveToGCS(data, filename, destination.config);
        break;
      case 'azure':
        await this.saveToAzure(data, filename, destination.config);
        break;
      case 'local':
        const fs = require('fs').promises;
        const path = require('path');
        const fullPath = path.join(destination.config.directory || '.', filename);
        await fs.writeFile(fullPath, data);
        console.log(`üíæ Exported to: ${fullPath}`);
        break;
    }
  }
  
  private async saveToS3(data: string, filename: string, config: any): Promise<void> {
    // Implementation depends on AWS SDK
    console.log(`‚òÅÔ∏è Uploading to S3: s3://${config.bucket}/${filename}`);
  }
  
  private async saveToGCS(data: string, filename: string, config: any): Promise<void> {
    // Implementation depends on Google Cloud Storage SDK
    console.log(`‚òÅÔ∏è Uploading to GCS: gs://${config.bucket}/${filename}`);
  }
  
  private async saveToAzure(data: string, filename: string, config: any): Promise<void> {
    // Implementation depends on Azure Storage SDK
    console.log(`‚òÅÔ∏è Uploading to Azure: ${config.container}/${filename}`);
  }
}

interface ExportResult {
  filename: string;
  recordCount: number;
  fileSize: number;
  duration: number;
  format: string;
  compressed: boolean;
}

// Usage
const exporter = new LogExporter(client);

// Export to JSON with compression
const jsonExport = await exporter.exportLogs({
  format: 'json',
  compression: 'gzip',
  filter: {
    timeframe: '7d',
    level: ['warn', 'error', 'fatal']
  },
  includeMetadata: true,
  destination: {
    type: 'local',
    config: {
      directory: './exports'
    }
  }
});

console.log('Export completed:', jsonExport);

// Export to CSV for analytics
const csvExport = await exporter.exportLogs({
  format: 'csv',
  filter: {
    timeframe: '30d',
    flowId: 'critical_business_flow'
  },
  includeMetadata: false,
  batchSize: 5000,
  destination: {
    type: 's3',
    config: {
      bucket: 'company-log-archives',
      region: 'us-west-2'
    }
  }
});
```

## Related Resources

<CardGroup cols={2}>
  <Card title="Log Analysis" icon="chart-line" href="/sdk/resources/execution-logs/analysis">
    Advanced log analysis and monitoring techniques
  </Card>
  <Card title="Log Export" icon="download" href="/sdk/resources/execution-logs/export">
    Export and archive logs for compliance and analysis
  </Card>
</CardGroup>

<CardGroup cols={2}>
  <Card title="Monitoring Guide" icon="shield-check" href="/sdk/guides/monitoring">
    Best practices for production log monitoring
  </Card>
  <Card title="Troubleshooting" icon="wrench" href="/sdk/guides/troubleshooting">
    Use logs to debug and troubleshoot issues
  </Card>
</CardGroup>

---

*The Execution Logs SDK provides comprehensive logging capabilities for monitoring, debugging, and analyzing your automation workflows. Use these patterns to build robust observability into your applications.*