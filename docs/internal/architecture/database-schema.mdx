---
title: 'Database Schema Documentation'
description: 'Comprehensive database schema documentation for Tolstoy platform including tables, relationships, indexes, and data models'
---

# Database Schema Documentation

This document provides comprehensive documentation of the Tolstoy platform database schema, including table structures, relationships, indexes, constraints, and data models across all microservices.

## Schema Overview

### Database Architecture

<CardGroup cols={2}>
  <Card title="Primary Database" icon="database">
    PostgreSQL 15 with multi-tenant row-level security for application data
  </Card>
  <Card title="Analytics Database" icon="chart-line">
    ClickHouse for high-performance analytics and time-series data
  </Card>
  <Card title="Cache Layer" icon="bolt">
    Redis for session storage, caching, and real-time data
  </Card>
  <Card title="Search Engine" icon="magnifying-glass">
    Elasticsearch for full-text search and complex queries
  </Card>
</CardGroup>

### Multi-Tenancy Strategy

```sql
-- Row-level security implementation
ALTER TABLE workflows ENABLE ROW LEVEL SECURITY;
ALTER TABLE executions ENABLE ROW LEVEL SECURITY;
ALTER TABLE integrations ENABLE ROW LEVEL SECURITY;

-- Organization-based access policy
CREATE POLICY org_isolation_policy ON workflows
  FOR ALL TO application_user
  USING (organization_id = current_setting('app.current_org_id')::uuid);

-- User context policy
CREATE POLICY user_access_policy ON user_sessions
  FOR ALL TO application_user  
  USING (user_id = current_setting('app.current_user_id')::uuid);
```

## Core Application Tables

### Organizations

```sql
CREATE TABLE organizations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    slug VARCHAR(100) UNIQUE NOT NULL,
    domain VARCHAR(255),
    plan VARCHAR(50) NOT NULL DEFAULT 'free',
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    settings JSONB DEFAULT '{}',
    billing_info JSONB DEFAULT '{}',
    limits JSONB DEFAULT '{
        "workflows": 10,
        "executions_per_month": 1000,
        "storage_gb": 1,
        "team_members": 5
    }',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_plan CHECK (plan IN ('free', 'starter', 'professional', 'enterprise')),
    CONSTRAINT valid_status CHECK (status IN ('active', 'suspended', 'deleted')),
    CONSTRAINT slug_format CHECK (slug ~ '^[a-z0-9-]+$')
);

-- Indexes
CREATE INDEX idx_organizations_status ON organizations(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_organizations_plan ON organizations(plan) WHERE deleted_at IS NULL;
CREATE INDEX idx_organizations_domain ON organizations(domain) WHERE domain IS NOT NULL;
CREATE INDEX idx_organizations_created_at ON organizations(created_at DESC);

-- Triggers
CREATE TRIGGER update_organizations_updated_at
    BEFORE UPDATE ON organizations
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### Users

```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    email_verified BOOLEAN DEFAULT FALSE,
    password_hash VARCHAR(255),
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    avatar_url TEXT,
    timezone VARCHAR(100) DEFAULT 'UTC',
    locale VARCHAR(10) DEFAULT 'en',
    preferences JSONB DEFAULT '{}',
    
    -- Authentication
    mfa_enabled BOOLEAN DEFAULT FALSE,
    mfa_secret VARCHAR(32),
    mfa_backup_codes TEXT[],
    password_reset_token VARCHAR(255),
    password_reset_expires TIMESTAMP WITH TIME ZONE,
    email_verification_token VARCHAR(255),
    
    -- Session tracking
    last_login_at TIMESTAMP WITH TIME ZONE,
    last_activity_at TIMESTAMP WITH TIME ZONE,
    login_count INTEGER DEFAULT 0,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_email CHECK (email ~* '^[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}$'),
    CONSTRAINT valid_status CHECK (status IN ('active', 'suspended', 'deleted')),
    CONSTRAINT valid_timezone CHECK (timezone IS NULL OR timezone ~ '^[A-Za-z/_]+$')
);

-- Indexes
CREATE INDEX idx_users_email ON users(email) WHERE deleted_at IS NULL;
CREATE INDEX idx_users_status ON users(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_users_last_activity ON users(last_activity_at DESC);
CREATE INDEX idx_users_created_at ON users(created_at DESC);

-- Triggers
CREATE TRIGGER update_users_updated_at
    BEFORE UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### Organization Members

```sql
CREATE TABLE organization_members (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    role VARCHAR(50) NOT NULL DEFAULT 'member',
    permissions TEXT[] DEFAULT '{}',
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    invited_by UUID REFERENCES users(id),
    invitation_token VARCHAR(255),
    invitation_expires TIMESTAMP WITH TIME ZONE,
    joined_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_role CHECK (role IN ('owner', 'admin', 'member', 'viewer')),
    CONSTRAINT valid_status CHECK (status IN ('active', 'inactive', 'pending')),
    CONSTRAINT unique_org_user UNIQUE(organization_id, user_id)
);

-- Indexes
CREATE INDEX idx_org_members_org_id ON organization_members(organization_id);
CREATE INDEX idx_org_members_user_id ON organization_members(user_id);
CREATE INDEX idx_org_members_role ON organization_members(role);
CREATE INDEX idx_org_members_status ON organization_members(status);
CREATE INDEX idx_org_members_invitation ON organization_members(invitation_token) WHERE invitation_token IS NOT NULL;

-- Row-level security
ALTER TABLE organization_members ENABLE ROW LEVEL SECURITY;
CREATE POLICY org_member_policy ON organization_members
    FOR ALL TO application_user
    USING (organization_id = current_setting('app.current_org_id')::uuid);
```

## Workflow Management Tables

### Workflows

```sql
CREATE TABLE workflows (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    
    -- Workflow definition
    trigger JSONB NOT NULL,
    actions JSONB NOT NULL DEFAULT '[]',
    variables JSONB DEFAULT '{}',
    settings JSONB DEFAULT '{}',
    
    -- Metadata
    category VARCHAR(100),
    tags TEXT[] DEFAULT '{}',
    version INTEGER NOT NULL DEFAULT 1,
    
    -- Status and lifecycle
    status VARCHAR(20) NOT NULL DEFAULT 'draft',
    is_template BOOLEAN DEFAULT FALSE,
    template_id UUID REFERENCES workflows(id),
    
    -- Usage tracking
    execution_count INTEGER DEFAULT 0,
    last_executed_at TIMESTAMP WITH TIME ZONE,
    
    -- Audit
    created_by UUID NOT NULL REFERENCES users(id),
    updated_by UUID REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_status CHECK (status IN ('draft', 'active', 'paused', 'archived')),
    CONSTRAINT valid_version CHECK (version > 0),
    CONSTRAINT trigger_required CHECK (jsonb_typeof(trigger) = 'object')
);

-- Indexes
CREATE INDEX idx_workflows_org_status ON workflows(organization_id, status) WHERE deleted_at IS NULL;
CREATE INDEX idx_workflows_created_by ON workflows(created_by);
CREATE INDEX idx_workflows_template ON workflows(template_id) WHERE template_id IS NOT NULL;
CREATE INDEX idx_workflows_category ON workflows(category) WHERE category IS NOT NULL;
CREATE INDEX idx_workflows_tags ON workflows USING GIN(tags);
CREATE INDEX idx_workflows_last_executed ON workflows(last_executed_at DESC);
CREATE INDEX idx_workflows_created_at ON workflows(created_at DESC);

-- Full-text search
CREATE INDEX idx_workflows_search ON workflows USING GIN(
    to_tsvector('english', COALESCE(name, '') || ' ' || COALESCE(description, ''))
);

-- Row-level security
ALTER TABLE workflows ENABLE ROW LEVEL SECURITY;
CREATE POLICY workflow_org_policy ON workflows
    FOR ALL TO application_user
    USING (organization_id = current_setting('app.current_org_id')::uuid);

-- Triggers
CREATE TRIGGER update_workflows_updated_at
    BEFORE UPDATE ON workflows
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### Workflow Versions

```sql
CREATE TABLE workflow_versions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    workflow_id UUID NOT NULL REFERENCES workflows(id) ON DELETE CASCADE,
    version INTEGER NOT NULL,
    
    -- Versioned content
    name VARCHAR(255) NOT NULL,
    description TEXT,
    trigger JSONB NOT NULL,
    actions JSONB NOT NULL DEFAULT '[]',
    variables JSONB DEFAULT '{}',
    settings JSONB DEFAULT '{}',
    
    -- Version metadata
    change_summary TEXT,
    is_published BOOLEAN DEFAULT FALSE,
    
    -- Audit
    created_by UUID NOT NULL REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT unique_workflow_version UNIQUE(workflow_id, version),
    CONSTRAINT valid_version CHECK (version > 0)
);

-- Indexes
CREATE INDEX idx_workflow_versions_workflow ON workflow_versions(workflow_id, version DESC);
CREATE INDEX idx_workflow_versions_published ON workflow_versions(workflow_id) WHERE is_published = TRUE;
```

### Executions

```sql
CREATE TABLE executions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    workflow_id UUID NOT NULL REFERENCES workflows(id) ON DELETE CASCADE,
    workflow_version INTEGER NOT NULL DEFAULT 1,
    
    -- Execution context
    trigger_data JSONB,
    input_data JSONB,
    output_data JSONB,
    variables JSONB DEFAULT '{}',
    
    -- Status tracking
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    current_step INTEGER DEFAULT 0,
    total_steps INTEGER DEFAULT 0,
    
    -- Performance metrics
    started_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE,
    duration_ms INTEGER,
    
    -- Error handling
    error_message TEXT,
    error_stack TEXT,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    
    -- Resource usage
    memory_used_mb REAL,
    cpu_time_ms INTEGER,
    
    -- Metadata
    execution_mode VARCHAR(20) DEFAULT 'production',
    triggered_by VARCHAR(50),
    correlation_id VARCHAR(255),
    parent_execution_id UUID REFERENCES executions(id),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_status CHECK (status IN ('pending', 'running', 'completed', 'failed', 'cancelled', 'timeout')),
    CONSTRAINT valid_execution_mode CHECK (execution_mode IN ('production', 'test', 'debug')),
    CONSTRAINT valid_retry_count CHECK (retry_count <= max_retries)
);

-- Indexes
CREATE INDEX idx_executions_workflow ON executions(workflow_id);
CREATE INDEX idx_executions_status ON executions(status);
CREATE INDEX idx_executions_started_at ON executions(started_at DESC);
CREATE INDEX idx_executions_completed_at ON executions(completed_at DESC) WHERE completed_at IS NOT NULL;
CREATE INDEX idx_executions_correlation ON executions(correlation_id) WHERE correlation_id IS NOT NULL;
CREATE INDEX idx_executions_parent ON executions(parent_execution_id) WHERE parent_execution_id IS NOT NULL;
CREATE INDEX idx_executions_duration ON executions(duration_ms DESC) WHERE duration_ms IS NOT NULL;

-- Composite indexes
CREATE INDEX idx_executions_workflow_status_date ON executions(workflow_id, status, started_at DESC);
CREATE INDEX idx_executions_status_date ON executions(status, started_at DESC);

-- Row-level security
ALTER TABLE executions ENABLE ROW LEVEL SECURITY;
CREATE POLICY execution_org_policy ON executions
    FOR ALL TO application_user
    USING (workflow_id IN (
        SELECT id FROM workflows WHERE organization_id = current_setting('app.current_org_id')::uuid
    ));

-- Triggers
CREATE TRIGGER update_executions_updated_at
    BEFORE UPDATE ON executions
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### Execution Steps

```sql
CREATE TABLE execution_steps (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    execution_id UUID NOT NULL REFERENCES executions(id) ON DELETE CASCADE,
    step_index INTEGER NOT NULL,
    step_name VARCHAR(255) NOT NULL,
    step_type VARCHAR(100) NOT NULL,
    
    -- Step configuration
    action_config JSONB NOT NULL,
    input_data JSONB,
    output_data JSONB,
    
    -- Status tracking
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    duration_ms INTEGER,
    
    -- Error handling
    error_message TEXT,
    error_code VARCHAR(100),
    retry_count INTEGER DEFAULT 0,
    
    -- Metadata
    provider VARCHAR(100),
    external_id VARCHAR(255),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_status CHECK (status IN ('pending', 'running', 'completed', 'failed', 'skipped')),
    CONSTRAINT unique_execution_step UNIQUE(execution_id, step_index)
);

-- Indexes
CREATE INDEX idx_execution_steps_execution ON execution_steps(execution_id, step_index);
CREATE INDEX idx_execution_steps_status ON execution_steps(status);
CREATE INDEX idx_execution_steps_type ON execution_steps(step_type);
CREATE INDEX idx_execution_steps_provider ON execution_steps(provider) WHERE provider IS NOT NULL;
CREATE INDEX idx_execution_steps_duration ON execution_steps(duration_ms DESC) WHERE duration_ms IS NOT NULL;
```

## Integration Management Tables

### Integrations

```sql
CREATE TABLE integrations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    provider VARCHAR(100) NOT NULL,
    provider_type VARCHAR(50) NOT NULL,
    
    -- Connection details
    config JSONB NOT NULL DEFAULT '{}',
    credentials JSONB, -- Encrypted
    auth_type VARCHAR(50) NOT NULL,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    last_tested_at TIMESTAMP WITH TIME ZONE,
    last_test_result JSONB,
    health_status VARCHAR(20) DEFAULT 'unknown',
    
    -- Usage tracking
    usage_count INTEGER DEFAULT 0,
    last_used_at TIMESTAMP WITH TIME ZONE,
    
    -- Rate limiting
    rate_limit_per_hour INTEGER,
    current_usage_count INTEGER DEFAULT 0,
    usage_reset_at TIMESTAMP WITH TIME ZONE,
    
    -- Metadata
    description TEXT,
    tags TEXT[] DEFAULT '{}',
    
    -- Audit
    created_by UUID NOT NULL REFERENCES users(id),
    updated_by UUID REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_provider_type CHECK (provider_type IN ('api', 'database', 'file', 'webhook', 'queue')),
    CONSTRAINT valid_auth_type CHECK (auth_type IN ('none', 'api_key', 'oauth2', 'basic', 'bearer')),
    CONSTRAINT valid_status CHECK (status IN ('active', 'inactive', 'error', 'testing')),
    CONSTRAINT valid_health_status CHECK (health_status IN ('healthy', 'degraded', 'unhealthy', 'unknown'))
);

-- Indexes
CREATE INDEX idx_integrations_org ON integrations(organization_id) WHERE deleted_at IS NULL;
CREATE INDEX idx_integrations_provider ON integrations(provider, provider_type);
CREATE INDEX idx_integrations_status ON integrations(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_integrations_health ON integrations(health_status);
CREATE INDEX idx_integrations_tags ON integrations USING GIN(tags);
CREATE INDEX idx_integrations_last_used ON integrations(last_used_at DESC);

-- Row-level security
ALTER TABLE integrations ENABLE ROW LEVEL SECURITY;
CREATE POLICY integration_org_policy ON integrations
    FOR ALL TO application_user
    USING (organization_id = current_setting('app.current_org_id')::uuid);
```

### Integration Logs

```sql
CREATE TABLE integration_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    integration_id UUID NOT NULL REFERENCES integrations(id) ON DELETE CASCADE,
    execution_id UUID REFERENCES executions(id) ON DELETE SET NULL,
    
    -- Request details
    method VARCHAR(20),
    url TEXT,
    headers JSONB,
    request_body JSONB,
    request_size INTEGER,
    
    -- Response details
    status_code INTEGER,
    response_headers JSONB,
    response_body JSONB,
    response_size INTEGER,
    
    -- Timing
    request_started_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    request_completed_at TIMESTAMP WITH TIME ZONE,
    duration_ms INTEGER,
    
    -- Error handling
    error_message TEXT,
    error_code VARCHAR(100),
    
    -- Metadata
    correlation_id VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_integration_logs_integration ON integration_logs(integration_id);
CREATE INDEX idx_integration_logs_execution ON integration_logs(execution_id) WHERE execution_id IS NOT NULL;
CREATE INDEX idx_integration_logs_status ON integration_logs(status_code);
CREATE INDEX idx_integration_logs_created_at ON integration_logs(created_at DESC);
CREATE INDEX idx_integration_logs_correlation ON integration_logs(correlation_id) WHERE correlation_id IS NOT NULL;

-- Partitioning by month for performance
CREATE TABLE integration_logs_y2024m01 PARTITION OF integration_logs
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

## Tool Management Tables

### Tools

```sql
CREATE TABLE tools (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    slug VARCHAR(100) UNIQUE NOT NULL,
    category VARCHAR(100) NOT NULL,
    
    -- Tool definition
    description TEXT NOT NULL,
    icon_url TEXT,
    provider VARCHAR(100) NOT NULL,
    version VARCHAR(50) NOT NULL DEFAULT '1.0.0',
    
    -- Configuration schema
    config_schema JSONB NOT NULL,
    auth_schema JSONB,
    input_schema JSONB,
    output_schema JSONB,
    
    -- Capabilities
    supports_batch BOOLEAN DEFAULT FALSE,
    supports_streaming BOOLEAN DEFAULT FALSE,
    max_batch_size INTEGER,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    is_public BOOLEAN DEFAULT TRUE,
    is_verified BOOLEAN DEFAULT FALSE,
    
    -- Documentation
    documentation_url TEXT,
    api_documentation JSONB,
    examples JSONB DEFAULT '[]',
    
    -- Metadata
    tags TEXT[] DEFAULT '{}',
    pricing_model VARCHAR(50),
    
    -- Audit
    created_by UUID REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_status CHECK (status IN ('active', 'deprecated', 'beta', 'alpha')),
    CONSTRAINT valid_pricing_model CHECK (pricing_model IN ('free', 'freemium', 'paid', 'usage_based'))
);

-- Indexes
CREATE INDEX idx_tools_category ON tools(category) WHERE status = 'active';
CREATE INDEX idx_tools_provider ON tools(provider);
CREATE INDEX idx_tools_status ON tools(status);
CREATE INDEX idx_tools_public ON tools(is_public, is_verified);
CREATE INDEX idx_tools_tags ON tools USING GIN(tags);
CREATE INDEX idx_tools_search ON tools USING GIN(
    to_tsvector('english', name || ' ' || COALESCE(description, ''))
);
```

### Tool Configurations

```sql
CREATE TABLE tool_configurations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    tool_id UUID NOT NULL REFERENCES tools(id) ON DELETE CASCADE,
    integration_id UUID REFERENCES integrations(id) ON DELETE SET NULL,
    
    -- Configuration
    name VARCHAR(255) NOT NULL,
    config JSONB NOT NULL DEFAULT '{}',
    auth_config JSONB, -- Encrypted
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    last_tested_at TIMESTAMP WITH TIME ZONE,
    test_result JSONB,
    
    -- Usage tracking
    usage_count INTEGER DEFAULT 0,
    last_used_at TIMESTAMP WITH TIME ZONE,
    
    -- Audit
    created_by UUID NOT NULL REFERENCES users(id),
    updated_by UUID REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_status CHECK (status IN ('active', 'inactive', 'error')),
    CONSTRAINT unique_org_tool_name UNIQUE(organization_id, tool_id, name) DEFERRABLE INITIALLY DEFERRED
);

-- Indexes
CREATE INDEX idx_tool_configs_org_tool ON tool_configurations(organization_id, tool_id);
CREATE INDEX idx_tool_configs_status ON tool_configurations(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_tool_configs_last_used ON tool_configurations(last_used_at DESC);

-- Row-level security
ALTER TABLE tool_configurations ENABLE ROW LEVEL SECURITY;
CREATE POLICY tool_config_org_policy ON tool_configurations
    FOR ALL TO application_user
    USING (organization_id = current_setting('app.current_org_id')::uuid);
```

## Webhook Management Tables

### Webhooks

```sql
CREATE TABLE webhooks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    
    -- Webhook configuration
    url TEXT NOT NULL,
    method VARCHAR(10) NOT NULL DEFAULT 'POST',
    headers JSONB DEFAULT '{}',
    auth_config JSONB, -- Encrypted
    
    -- Event filtering
    events TEXT[] NOT NULL DEFAULT '{}',
    event_filters JSONB DEFAULT '{}',
    
    -- Delivery settings
    timeout_ms INTEGER DEFAULT 30000,
    retry_attempts INTEGER DEFAULT 3,
    retry_backoff VARCHAR(20) DEFAULT 'exponential',
    
    -- Security
    secret VARCHAR(255) NOT NULL,
    signature_header VARCHAR(100) DEFAULT 'X-Tolstoy-Signature',
    verify_ssl BOOLEAN DEFAULT TRUE,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    last_delivery_at TIMESTAMP WITH TIME ZONE,
    last_delivery_status VARCHAR(20),
    consecutive_failures INTEGER DEFAULT 0,
    
    -- Audit
    created_by UUID NOT NULL REFERENCES users(id),
    updated_by UUID REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_method CHECK (method IN ('POST', 'PUT', 'PATCH')),
    CONSTRAINT valid_status CHECK (status IN ('active', 'paused', 'failed', 'deleted')),
    CONSTRAINT valid_retry_backoff CHECK (retry_backoff IN ('linear', 'exponential')),
    CONSTRAINT valid_timeout CHECK (timeout_ms BETWEEN 1000 AND 60000),
    CONSTRAINT valid_retry_attempts CHECK (retry_attempts BETWEEN 0 AND 10)
);

-- Indexes
CREATE INDEX idx_webhooks_org ON webhooks(organization_id) WHERE deleted_at IS NULL;
CREATE INDEX idx_webhooks_status ON webhooks(status);
CREATE INDEX idx_webhooks_events ON webhooks USING GIN(events);
CREATE INDEX idx_webhooks_last_delivery ON webhooks(last_delivery_at DESC);
CREATE INDEX idx_webhooks_failures ON webhooks(consecutive_failures) WHERE consecutive_failures > 0;

-- Row-level security
ALTER TABLE webhooks ENABLE ROW LEVEL SECURITY;
CREATE POLICY webhook_org_policy ON webhooks
    FOR ALL TO application_user
    USING (organization_id = current_setting('app.current_org_id')::uuid);
```

### Webhook Deliveries

```sql
CREATE TABLE webhook_deliveries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    webhook_id UUID NOT NULL REFERENCES webhooks(id) ON DELETE CASCADE,
    execution_id UUID REFERENCES executions(id) ON DELETE SET NULL,
    
    -- Event data
    event_type VARCHAR(100) NOT NULL,
    event_data JSONB NOT NULL,
    
    -- Request details
    request_url TEXT NOT NULL,
    request_method VARCHAR(10) NOT NULL,
    request_headers JSONB,
    request_body JSONB,
    request_size INTEGER,
    
    -- Response details
    response_status INTEGER,
    response_headers JSONB,
    response_body TEXT,
    response_size INTEGER,
    
    -- Timing
    attempted_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE,
    duration_ms INTEGER,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    attempt_number INTEGER DEFAULT 1,
    error_message TEXT,
    
    -- Metadata
    correlation_id VARCHAR(255),
    next_retry_at TIMESTAMP WITH TIME ZONE,
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_status CHECK (status IN ('pending', 'success', 'failed', 'timeout', 'cancelled'))
);

-- Indexes
CREATE INDEX idx_webhook_deliveries_webhook ON webhook_deliveries(webhook_id);
CREATE INDEX idx_webhook_deliveries_execution ON webhook_deliveries(execution_id) WHERE execution_id IS NOT NULL;
CREATE INDEX idx_webhook_deliveries_status ON webhook_deliveries(status);
CREATE INDEX idx_webhook_deliveries_attempted_at ON webhook_deliveries(attempted_at DESC);
CREATE INDEX idx_webhook_deliveries_retry ON webhook_deliveries(next_retry_at) WHERE next_retry_at IS NOT NULL;
CREATE INDEX idx_webhook_deliveries_correlation ON webhook_deliveries(correlation_id) WHERE correlation_id IS NOT NULL;

-- Partitioning by month
CREATE TABLE webhook_deliveries_y2024m01 PARTITION OF webhook_deliveries
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

## Authentication & Session Management

### API Keys

```sql
CREATE TABLE api_keys (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    user_id UUID REFERENCES users(id) ON DELETE SET NULL,
    
    -- Key details
    name VARCHAR(255) NOT NULL,
    key_hash VARCHAR(255) NOT NULL UNIQUE, -- bcrypt hash of the key
    key_prefix VARCHAR(20) NOT NULL, -- First few characters for identification
    
    -- Permissions
    scopes TEXT[] DEFAULT '{}',
    ip_whitelist INET[],
    
    -- Usage
    last_used_at TIMESTAMP WITH TIME ZONE,
    usage_count INTEGER DEFAULT 0,
    
    -- Rate limiting
    rate_limit_per_hour INTEGER,
    current_usage INTEGER DEFAULT 0,
    usage_window_start TIMESTAMP WITH TIME ZONE,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    expires_at TIMESTAMP WITH TIME ZONE,
    
    -- Audit
    created_by UUID NOT NULL REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_status CHECK (status IN ('active', 'inactive', 'expired', 'revoked'))
);

-- Indexes
CREATE INDEX idx_api_keys_org ON api_keys(organization_id) WHERE deleted_at IS NULL;
CREATE INDEX idx_api_keys_hash ON api_keys(key_hash) WHERE status = 'active';
CREATE INDEX idx_api_keys_prefix ON api_keys(key_prefix);
CREATE INDEX idx_api_keys_status ON api_keys(status);
CREATE INDEX idx_api_keys_expires ON api_keys(expires_at) WHERE expires_at IS NOT NULL;
CREATE INDEX idx_api_keys_last_used ON api_keys(last_used_at DESC);

-- Row-level security
ALTER TABLE api_keys ENABLE ROW LEVEL SECURITY;
CREATE POLICY api_key_org_policy ON api_keys
    FOR ALL TO application_user
    USING (organization_id = current_setting('app.current_org_id')::uuid);
```

### User Sessions

```sql
CREATE TABLE user_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    organization_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
    
    -- Session details
    session_token VARCHAR(255) NOT NULL UNIQUE,
    refresh_token VARCHAR(255) UNIQUE,
    
    -- Client information
    user_agent TEXT,
    ip_address INET,
    location JSONB, -- City, country, etc.
    device_info JSONB,
    
    -- Status
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    last_activity_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    expires_at TIMESTAMP WITH TIME ZONE NOT NULL,
    
    -- Security
    is_mfa_verified BOOLEAN DEFAULT FALSE,
    login_method VARCHAR(50),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_status CHECK (status IN ('active', 'expired', 'revoked')),
    CONSTRAINT valid_login_method CHECK (login_method IN ('password', 'oauth', 'sso', 'api_key'))
);

-- Indexes
CREATE INDEX idx_user_sessions_user ON user_sessions(user_id);
CREATE INDEX idx_user_sessions_org ON user_sessions(organization_id) WHERE organization_id IS NOT NULL;
CREATE INDEX idx_user_sessions_token ON user_sessions(session_token) WHERE status = 'active';
CREATE INDEX idx_user_sessions_status ON user_sessions(status);
CREATE INDEX idx_user_sessions_expires ON user_sessions(expires_at);
CREATE INDEX idx_user_sessions_activity ON user_sessions(last_activity_at DESC);

-- Auto-expire sessions
CREATE INDEX idx_user_sessions_cleanup ON user_sessions(expires_at) WHERE status = 'active';
```

## Analytics Tables (ClickHouse)

### Execution Analytics

```sql
-- ClickHouse table for execution metrics
CREATE TABLE execution_events (
    timestamp DateTime64(3),
    event_id UUID,
    execution_id UUID,
    workflow_id UUID,
    organization_id UUID,
    user_id Nullable(UUID),
    
    -- Event details
    event_type LowCardinality(String),
    event_data String, -- JSON string
    
    -- Performance metrics
    duration_ms UInt32,
    memory_used_mb Float32,
    cpu_time_ms UInt32,
    
    -- Status
    success Bool,
    error_code Nullable(String),
    error_message Nullable(String),
    
    -- Context
    workflow_version UInt16,
    step_index Nullable(UInt16),
    step_name Nullable(String),
    
    -- Metadata
    correlation_id Nullable(String),
    user_agent Nullable(String),
    ip_address Nullable(IPv4),
    
    -- Dimensions for analytics
    date Date MATERIALIZED toDate(timestamp),
    hour UInt8 MATERIALIZED toHour(timestamp)
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(timestamp)
ORDER BY (organization_id, workflow_id, timestamp)
TTL timestamp + INTERVAL 2 YEAR;

-- Materialized views for common queries
CREATE MATERIALIZED VIEW execution_hourly_stats
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (organization_id, workflow_id, date, hour)
AS SELECT
    organization_id,
    workflow_id,
    toDate(timestamp) as date,
    toHour(timestamp) as hour,
    count() as execution_count,
    countIf(success) as success_count,
    countIf(NOT success) as error_count,
    avg(duration_ms) as avg_duration_ms,
    quantile(0.95)(duration_ms) as p95_duration_ms,
    sum(memory_used_mb) as total_memory_mb,
    sum(cpu_time_ms) as total_cpu_ms
FROM execution_events
GROUP BY organization_id, workflow_id, date, hour;
```

### API Usage Analytics

```sql
CREATE TABLE api_requests (
    timestamp DateTime64(3),
    request_id UUID,
    organization_id UUID,
    user_id Nullable(UUID),
    api_key_id Nullable(UUID),
    
    -- Request details
    method LowCardinality(String),
    endpoint String,
    path_pattern LowCardinality(String),
    query_params String,
    
    -- Response details
    status_code UInt16,
    response_time_ms UInt32,
    request_size UInt32,
    response_size UInt32,
    
    -- Client information
    ip_address IPv4,
    user_agent String,
    referer Nullable(String),
    
    -- Geographic data
    country LowCardinality(String),
    city LowCardinality(String),
    
    -- Error information
    error_code Nullable(String),
    error_message Nullable(String),
    
    -- Dimensions
    date Date MATERIALIZED toDate(timestamp),
    hour UInt8 MATERIALIZED toHour(timestamp)
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(timestamp)
ORDER BY (organization_id, path_pattern, timestamp)
TTL timestamp + INTERVAL 1 YEAR;

-- API usage summary view
CREATE MATERIALIZED VIEW api_usage_daily
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (organization_id, path_pattern, date)
AS SELECT
    organization_id,
    path_pattern,
    method,
    toDate(timestamp) as date,
    count() as request_count,
    countIf(status_code < 400) as success_count,
    countIf(status_code >= 400 AND status_code < 500) as client_error_count,
    countIf(status_code >= 500) as server_error_count,
    avg(response_time_ms) as avg_response_time,
    quantile(0.95)(response_time_ms) as p95_response_time,
    sum(request_size) as total_request_size,
    sum(response_size) as total_response_size
FROM api_requests
GROUP BY organization_id, path_pattern, method, date;
```

## Database Functions & Triggers

### Utility Functions

```sql
-- Update timestamp function
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Generate API key function
CREATE OR REPLACE FUNCTION generate_api_key()
RETURNS TEXT AS $$
DECLARE
    key_length INT := 32;
    key_chars TEXT := 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
    result TEXT := '';
    i INT;
BEGIN
    FOR i IN 1..key_length LOOP
        result := result || substr(key_chars, (random() * length(key_chars))::int + 1, 1);
    END LOOP;
    RETURN 'tol_' || result;
END;
$$ LANGUAGE plpgsql;

-- Encrypt sensitive data function
CREATE OR REPLACE FUNCTION encrypt_field(data TEXT, key TEXT)
RETURNS TEXT AS $$
BEGIN
    RETURN encode(encrypt(data::bytea, key::bytea, 'aes'), 'base64');
END;
$$ LANGUAGE plpgsql;

-- Decrypt sensitive data function  
CREATE OR REPLACE FUNCTION decrypt_field(data TEXT, key TEXT)
RETURNS TEXT AS $$
BEGIN
    RETURN convert_from(decrypt(decode(data, 'base64'), key::bytea, 'aes'), 'UTF8');
END;
$$ LANGUAGE plpgsql;
```

### Audit Triggers

```sql
-- Audit log table
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    table_name VARCHAR(100) NOT NULL,
    record_id UUID NOT NULL,
    operation VARCHAR(10) NOT NULL,
    old_values JSONB,
    new_values JSONB,
    changed_fields TEXT[],
    user_id UUID REFERENCES users(id),
    organization_id UUID REFERENCES organizations(id),
    ip_address INET,
    user_agent TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    CONSTRAINT valid_operation CHECK (operation IN ('INSERT', 'UPDATE', 'DELETE'))
);

-- Audit trigger function
CREATE OR REPLACE FUNCTION audit_trigger_function()
RETURNS TRIGGER AS $$
DECLARE
    old_data JSONB;
    new_data JSONB;
    changed_fields TEXT[];
    key TEXT;
BEGIN
    -- Get current user context
    DECLARE
        current_user_id UUID := COALESCE(current_setting('app.current_user_id', true)::UUID, NULL);
        current_org_id UUID := COALESCE(current_setting('app.current_org_id', true)::UUID, NULL);
        current_ip INET := COALESCE(current_setting('app.client_ip', true)::INET, NULL);
        current_ua TEXT := COALESCE(current_setting('app.user_agent', true), NULL);
    BEGIN
        IF TG_OP = 'DELETE' THEN
            old_data := to_jsonb(OLD);
            INSERT INTO audit_logs (
                table_name, record_id, operation, old_values,
                user_id, organization_id, ip_address, user_agent
            ) VALUES (
                TG_TABLE_NAME, OLD.id, TG_OP, old_data,
                current_user_id, current_org_id, current_ip, current_ua
            );
            RETURN OLD;
        ELSIF TG_OP = 'UPDATE' THEN
            old_data := to_jsonb(OLD);
            new_data := to_jsonb(NEW);
            
            -- Find changed fields
            FOR key IN SELECT jsonb_object_keys(new_data) LOOP
                IF old_data->key IS DISTINCT FROM new_data->key THEN
                    changed_fields := array_append(changed_fields, key);
                END IF;
            END LOOP;
            
            INSERT INTO audit_logs (
                table_name, record_id, operation, old_values, new_values, changed_fields,
                user_id, organization_id, ip_address, user_agent
            ) VALUES (
                TG_TABLE_NAME, NEW.id, TG_OP, old_data, new_data, changed_fields,
                current_user_id, current_org_id, current_ip, current_ua
            );
            RETURN NEW;
        ELSIF TG_OP = 'INSERT' THEN
            new_data := to_jsonb(NEW);
            INSERT INTO audit_logs (
                table_name, record_id, operation, new_values,
                user_id, organization_id, ip_address, user_agent
            ) VALUES (
                TG_TABLE_NAME, NEW.id, TG_OP, new_data,
                current_user_id, current_org_id, current_ip, current_ua
            );
            RETURN NEW;
        END IF;
        RETURN NULL;
    END;
END;
$$ LANGUAGE plpgsql;

-- Apply audit triggers to sensitive tables
CREATE TRIGGER workflows_audit_trigger
    AFTER INSERT OR UPDATE OR DELETE ON workflows
    FOR EACH ROW EXECUTE FUNCTION audit_trigger_function();

CREATE TRIGGER integrations_audit_trigger
    AFTER INSERT OR UPDATE OR DELETE ON integrations
    FOR EACH ROW EXECUTE FUNCTION audit_trigger_function();

CREATE TRIGGER api_keys_audit_trigger
    AFTER INSERT OR UPDATE OR DELETE ON api_keys
    FOR EACH ROW EXECUTE FUNCTION audit_trigger_function();
```

## Data Retention Policies

### Automated Cleanup Jobs

```sql
-- Cleanup old executions (keep 90 days)
CREATE OR REPLACE FUNCTION cleanup_old_executions()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM executions 
    WHERE completed_at < NOW() - INTERVAL '90 days'
    AND status IN ('completed', 'failed');
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;

-- Cleanup old execution steps
CREATE OR REPLACE FUNCTION cleanup_old_execution_steps()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM execution_steps 
    WHERE execution_id NOT IN (SELECT id FROM executions);
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;

-- Cleanup old webhook deliveries (keep 30 days)
CREATE OR REPLACE FUNCTION cleanup_old_webhook_deliveries()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM webhook_deliveries 
    WHERE attempted_at < NOW() - INTERVAL '30 days';
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;

-- Cleanup old integration logs (keep 7 days)
CREATE OR REPLACE FUNCTION cleanup_old_integration_logs()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM integration_logs 
    WHERE created_at < NOW() - INTERVAL '7 days';
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;

-- Cleanup expired sessions
CREATE OR REPLACE FUNCTION cleanup_expired_sessions()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM user_sessions 
    WHERE expires_at < NOW() 
    OR (status = 'active' AND last_activity_at < NOW() - INTERVAL '30 days');
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;
```

### Scheduled Maintenance

```sql
-- Create maintenance log table
CREATE TABLE maintenance_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_name VARCHAR(100) NOT NULL,
    status VARCHAR(20) NOT NULL,
    records_affected INTEGER,
    duration_ms INTEGER,
    error_message TEXT,
    started_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    completed_at TIMESTAMP WITH TIME ZONE,

    CONSTRAINT valid_status CHECK (status IN ('running', 'completed', 'failed'))
);

-- Master maintenance function
CREATE OR REPLACE FUNCTION run_maintenance_tasks()
RETURNS TABLE(task_name VARCHAR, status VARCHAR, records_affected INTEGER, duration_ms INTEGER) AS $$
DECLARE
    task VARCHAR;
    start_time TIMESTAMP WITH TIME ZONE;
    end_time TIMESTAMP WITH TIME ZONE;
    duration INTEGER;
    affected INTEGER;
    log_id UUID;
BEGIN
    -- Cleanup old executions
    task := 'cleanup_old_executions';
    start_time := NOW();
    INSERT INTO maintenance_logs (task_name, status) VALUES (task, 'running') RETURNING id INTO log_id;
    
    SELECT cleanup_old_executions() INTO affected;
    end_time := NOW();
    duration := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    UPDATE maintenance_logs SET 
        status = 'completed', 
        records_affected = affected, 
        duration_ms = duration,
        completed_at = end_time
    WHERE id = log_id;
    
    RETURN QUERY SELECT task, 'completed'::VARCHAR, affected, duration;

    -- Cleanup execution steps
    task := 'cleanup_old_execution_steps';
    start_time := NOW();
    INSERT INTO maintenance_logs (task_name, status) VALUES (task, 'running') RETURNING id INTO log_id;
    
    SELECT cleanup_old_execution_steps() INTO affected;
    end_time := NOW();
    duration := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    UPDATE maintenance_logs SET 
        status = 'completed', 
        records_affected = affected, 
        duration_ms = duration,
        completed_at = end_time
    WHERE id = log_id;
    
    RETURN QUERY SELECT task, 'completed'::VARCHAR, affected, duration;

    -- Additional cleanup tasks...
    -- (Similar pattern for other cleanup functions)
END;
$$ LANGUAGE plpgsql;
```

## Performance Optimizations

### Database Configuration

```sql
-- Performance-related settings
ALTER SYSTEM SET shared_buffers = '1GB';
ALTER SYSTEM SET effective_cache_size = '3GB';
ALTER SYSTEM SET maintenance_work_mem = '256MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.7;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;

-- Connection pooling
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET max_worker_processes = 8;
ALTER SYSTEM SET max_parallel_workers_per_gather = 2;
ALTER SYSTEM SET max_parallel_workers = 8;
```

### Query Performance Views

```sql
-- Slow query monitoring view
CREATE VIEW slow_queries AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    stddev_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
ORDER BY total_time DESC;

-- Table size monitoring
CREATE VIEW table_sizes AS
SELECT 
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation,
    most_common_vals,
    most_common_freqs,
    histogram_bounds
FROM pg_stats
WHERE schemaname = 'public'
ORDER BY schemaname, tablename;

-- Index usage statistics
CREATE VIEW index_usage AS
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_tup_read,
    idx_tup_fetch,
    idx_scan,
    idx_tup_read / NULLIF(idx_scan, 0) as avg_tuples_per_scan
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;
```

This comprehensive database schema documentation provides the foundation for the Tolstoy platform's data architecture, including multi-tenant security, performance optimizations, and operational maintenance procedures.